{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/punyajoy/HateXplain.git"
      ],
      "metadata": {
        "id": "Q1szy1aV2YpD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FPAJpqcYVEM0"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5l4M1_SHtDIm",
        "outputId": "cf16df9d-de53-48ec-f40a-58b8ffa0bfe0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/HateXplain\n"
          ]
        }
      ],
      "source": [
        "cd HateXplain/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vl3PF9alWjHx"
      },
      "outputs": [],
      "source": [
        "!mkdir Saved/\n",
        "!mkdir explanations_dicts/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qU8P_dV5Wnk5",
        "outputId": "82c28c76-7055-4f04-daec-a44645b59003"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-10-22 13:22:37--  http://nlp.stanford.edu/data/glove.42B.300d.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.42B.300d.zip [following]\n",
            "--2022-10-22 13:22:37--  https://nlp.stanford.edu/data/glove.42B.300d.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://downloads.cs.stanford.edu/nlp/data/glove.42B.300d.zip [following]\n",
            "--2022-10-22 13:22:38--  https://downloads.cs.stanford.edu/nlp/data/glove.42B.300d.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1877800501 (1.7G) [application/zip]\n",
            "Saving to: ‘Data/glove.42B.300d.zip’\n",
            "\n",
            "glove.42B.300d.zip  100%[===================>]   1.75G  4.98MB/s    in 5m 53s  \n",
            "\n",
            "2022-10-22 13:28:32 (5.07 MB/s) - ‘Data/glove.42B.300d.zip’ saved [1877800501/1877800501]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.42B.300d.zip  -P Data/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WZi9IlH-W_83",
        "outputId": "6d7ba3c8-f5f1-4e0b-a377-07b57841f752"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  Data/glove.42B.300d.zip\n",
            "  inflating: Data/glove.42B.300d.txt  \n"
          ]
        }
      ],
      "source": [
        "!unzip Data/glove.42B.300d.zip -d Data/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gofRAO-crNgI"
      },
      "outputs": [],
      "source": [
        "!rm Data/glove.42B.300d.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "dkIaNCQDgvSP",
        "outputId": "f6210d8c-85d0-4ce7-a0f4-759f5b2428ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting scipy==1.4.1\n",
            "  Downloading scipy-1.4.1-cp37-cp37m-manylinux1_x86_64.whl (26.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 26.1 MB 1.3 MB/s \n",
            "\u001b[?25hCollecting tqdm==4.43.0\n",
            "  Downloading tqdm-4.43.0-py2.py3-none-any.whl (59 kB)\n",
            "\u001b[K     |████████████████████████████████| 59 kB 5.4 MB/s \n",
            "\u001b[?25hCollecting Keras==2.3.1\n",
            "  Downloading Keras-2.3.1-py2.py3-none-any.whl (377 kB)\n",
            "\u001b[K     |████████████████████████████████| 377 kB 75.4 MB/s \n",
            "\u001b[?25hCollecting waiting==1.4.1\n",
            "  Downloading waiting-1.4.1.tar.gz (7.1 kB)\n",
            "Collecting ekphrasis==0.5.1\n",
            "  Downloading ekphrasis-0.5.1.tar.gz (80 kB)\n",
            "\u001b[K     |████████████████████████████████| 80 kB 9.5 MB/s \n",
            "\u001b[?25hCollecting pandas==1.0.3\n",
            "  Downloading pandas-1.0.3-cp37-cp37m-manylinux1_x86_64.whl (10.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.0 MB 24.4 MB/s \n",
            "\u001b[?25hCollecting transformers==2.5.1\n",
            "  Downloading transformers-2.5.1-py3-none-any.whl (499 kB)\n",
            "\u001b[K     |████████████████████████████████| 499 kB 64.0 MB/s \n",
            "\u001b[?25hCollecting lime==0.2.0.1\n",
            "  Downloading lime-0.2.0.1.tar.gz (275 kB)\n",
            "\u001b[K     |████████████████████████████████| 275 kB 68.6 MB/s \n",
            "\u001b[?25hCollecting numpy==1.16.3\n",
            "  Downloading numpy-1.16.3-cp37-cp37m-manylinux1_x86_64.whl (17.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 17.3 MB 20.1 MB/s \n",
            "\u001b[?25hCollecting matplotlib==3.2.1\n",
            "  Downloading matplotlib-3.2.1-cp37-cp37m-manylinux1_x86_64.whl (12.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.4 MB 53.9 MB/s \n",
            "\u001b[?25hCollecting gensim==3.8.1\n",
            "  Downloading gensim-3.8.1-cp37-cp37m-manylinux1_x86_64.whl (24.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 24.2 MB 1.3 MB/s \n",
            "\u001b[?25hCollecting neptune_client==0.4.107\n",
            "  Downloading neptune-client-0.4.107.tar.gz (86 kB)\n",
            "\u001b[K     |████████████████████████████████| 86 kB 6.9 MB/s \n",
            "\u001b[?25hCollecting knockknock==0.1.7\n",
            "  Downloading knockknock-0.1.7-py3-none-any.whl (19 kB)\n",
            "Collecting torch==1.1.0\n",
            "  Downloading torch-1.1.0-cp37-cp37m-manylinux1_x86_64.whl (676.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 676.9 MB 4.0 kB/s \n",
            "\u001b[?25hCollecting apex==0.9.10dev\n",
            "  Downloading apex-0.9.10dev.tar.gz (36 kB)\n",
            "Collecting dataclasses==0.6\n",
            "  Downloading dataclasses-0.6-py3-none-any.whl (14 kB)\n",
            "Collecting GPUtil==1.4.0\n",
            "  Downloading GPUtil-1.4.0.tar.gz (5.5 kB)\n",
            "Collecting scikit_learn==0.23.2\n",
            "  Downloading scikit_learn-0.23.2-cp37-cp37m-manylinux1_x86_64.whl (6.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.8 MB 51.2 MB/s \n",
            "\u001b[?25hCollecting keras-applications>=1.0.6\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 6.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from Keras==2.3.1->-r requirements.txt (line 4)) (1.1.2)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from Keras==2.3.1->-r requirements.txt (line 4)) (1.15.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from Keras==2.3.1->-r requirements.txt (line 4)) (6.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from Keras==2.3.1->-r requirements.txt (line 4)) (3.1.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.7/dist-packages (from ekphrasis==0.5.1->-r requirements.txt (line 6)) (2.0.1)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.5-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: ujson in /usr/local/lib/python3.7/dist-packages (from ekphrasis==0.5.1->-r requirements.txt (line 6)) (5.5.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from ekphrasis==0.5.1->-r requirements.txt (line 6)) (3.7)\n",
            "Collecting ftfy\n",
            "  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
            "\u001b[K     |████████████████████████████████| 53 kB 2.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas==1.0.3->-r requirements.txt (line 7)) (2022.4)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from pandas==1.0.3->-r requirements.txt (line 7)) (2.8.2)\n",
            "Collecting tokenizers==0.5.2\n",
            "  Downloading tokenizers-0.5.2-cp37-cp37m-manylinux1_x86_64.whl (5.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.6 MB 22.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==2.5.1->-r requirements.txt (line 8)) (3.8.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==2.5.1->-r requirements.txt (line 8)) (2022.6.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==2.5.1->-r requirements.txt (line 8)) (2.23.0)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.97-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 50.3 MB/s \n",
            "\u001b[?25hCollecting boto3\n",
            "  Downloading boto3-1.24.96-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 70.7 MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[K     |████████████████████████████████| 880 kB 79.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-image>=0.12 in /usr/local/lib/python3.7/dist-packages (from lime==0.2.0.1->-r requirements.txt (line 9)) (0.18.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.2.1->-r requirements.txt (line 11)) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.2.1->-r requirements.txt (line 11)) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.2.1->-r requirements.txt (line 11)) (1.4.4)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from gensim==3.8.1->-r requirements.txt (line 12)) (5.2.1)\n",
            "Collecting bravado\n",
            "  Downloading bravado-11.0.3-py2.py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from neptune_client==0.4.107->-r requirements.txt (line 13)) (7.1.2)\n",
            "Collecting future>=0.17.1\n",
            "  Downloading future-0.18.2.tar.gz (829 kB)\n",
            "\u001b[K     |████████████████████████████████| 829 kB 65.4 MB/s \n",
            "\u001b[?25hCollecting py3nvml\n",
            "  Downloading py3nvml-0.2.7-py3-none-any.whl (55 kB)\n",
            "\u001b[K     |████████████████████████████████| 55 kB 4.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: oauthlib>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from neptune_client==0.4.107->-r requirements.txt (line 13)) (3.2.1)\n",
            "Requirement already satisfied: Pillow>=1.1.6 in /usr/local/lib/python3.7/dist-packages (from neptune_client==0.4.107->-r requirements.txt (line 13)) (7.1.2)\n",
            "Collecting PyJWT\n",
            "  Downloading PyJWT-2.6.0-py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: requests-oauthlib>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from neptune_client==0.4.107->-r requirements.txt (line 13)) (1.3.1)\n",
            "Collecting websocket-client>=0.35.0\n",
            "  Downloading websocket_client-1.4.1-py3-none-any.whl (55 kB)\n",
            "\u001b[K     |████████████████████████████████| 55 kB 3.4 MB/s \n",
            "\u001b[?25hCollecting GitPython>=2.0.8\n",
            "  Downloading GitPython-3.1.29-py3-none-any.whl (182 kB)\n",
            "\u001b[K     |████████████████████████████████| 182 kB 72.9 MB/s \n",
            "\u001b[?25hCollecting python-telegram-bot\n",
            "  Downloading python_telegram_bot-13.14-py3-none-any.whl (514 kB)\n",
            "\u001b[K     |████████████████████████████████| 514 kB 70.5 MB/s \n",
            "\u001b[?25hCollecting yagmail>=0.11.214\n",
            "  Downloading yagmail-0.15.293-py2.py3-none-any.whl (17 kB)\n",
            "Collecting keyring\n",
            "  Downloading keyring-23.9.3-py3-none-any.whl (35 kB)\n",
            "Collecting matrix-client\n",
            "  Downloading matrix_client-0.4.0-py2.py3-none-any.whl (43 kB)\n",
            "\u001b[K     |████████████████████████████████| 43 kB 2.1 MB/s \n",
            "\u001b[?25hCollecting twilio\n",
            "  Downloading twilio-7.15.0-py2.py3-none-any.whl (1.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4 MB 49.8 MB/s \n",
            "\u001b[?25hCollecting cryptacular\n",
            "  Downloading cryptacular-1.6.2.tar.gz (75 kB)\n",
            "\u001b[K     |████████████████████████████████| 75 kB 3.6 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting zope.sqlalchemy\n",
            "  Downloading zope.sqlalchemy-1.6-py2.py3-none-any.whl (22 kB)\n",
            "Collecting velruse>=1.0.3\n",
            "  Downloading velruse-1.1.1.tar.gz (709 kB)\n",
            "\u001b[K     |████████████████████████████████| 709 kB 61.3 MB/s \n",
            "\u001b[?25hCollecting pyramid>1.1.2\n",
            "  Downloading pyramid-2.0-py3-none-any.whl (246 kB)\n",
            "\u001b[K     |████████████████████████████████| 246 kB 62.0 MB/s \n",
            "\u001b[?25hCollecting pyramid_mailer\n",
            "  Downloading pyramid_mailer-0.15.1-py2.py3-none-any.whl (19 kB)\n",
            "Collecting wtforms\n",
            "  Downloading WTForms-3.0.1-py3-none-any.whl (136 kB)\n",
            "\u001b[K     |████████████████████████████████| 136 kB 73.5 MB/s \n",
            "\u001b[?25hCollecting wtforms-recaptcha\n",
            "  Downloading wtforms_recaptcha-0.3.2-py2.py3-none-any.whl (7.5 kB)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit_learn==0.23.2->-r requirements.txt (line 19)) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit_learn==0.23.2->-r requirements.txt (line 19)) (3.1.0)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython>=2.0.8->neptune_client==0.4.107->-r requirements.txt (line 13)) (4.1.1)\n",
            "Collecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Collecting plaster-pastedeploy\n",
            "  Downloading plaster_pastedeploy-0.7-py2.py3-none-any.whl (7.8 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from pyramid>1.1.2->apex==0.9.10dev->-r requirements.txt (line 16)) (57.4.0)\n",
            "Collecting zope.deprecation>=3.5.0\n",
            "  Downloading zope.deprecation-4.4.0-py2.py3-none-any.whl (10 kB)\n",
            "Collecting zope.interface>=3.8.0\n",
            "  Downloading zope.interface-5.5.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (254 kB)\n",
            "\u001b[K     |████████████████████████████████| 254 kB 72.3 MB/s \n",
            "\u001b[?25hCollecting translationstring>=0.4\n",
            "  Downloading translationstring-1.4-py2.py3-none-any.whl (15 kB)\n",
            "Collecting venusian>=1.0\n",
            "  Downloading venusian-3.0.0-py3-none-any.whl (13 kB)\n",
            "Collecting hupper>=1.5\n",
            "  Downloading hupper-1.10.3-py2.py3-none-any.whl (26 kB)\n",
            "Collecting plaster\n",
            "  Downloading plaster-1.0-py2.py3-none-any.whl (14 kB)\n",
            "Collecting webob>=1.8.3\n",
            "  Downloading WebOb-1.8.7-py2.py3-none-any.whl (114 kB)\n",
            "\u001b[K     |████████████████████████████████| 114 kB 71.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.5.1->-r requirements.txt (line 8)) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.5.1->-r requirements.txt (line 8)) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.5.1->-r requirements.txt (line 8)) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.5.1->-r requirements.txt (line 8)) (2022.9.24)\n",
            "Collecting scikit-image>=0.12\n",
            "  Downloading scikit_image-0.19.3-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (13.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 13.5 MB 57.6 MB/s \n",
            "\u001b[?25h  Downloading scikit_image-0.19.2-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (13.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 13.5 MB 46.5 MB/s \n",
            "\u001b[?25h  Downloading scikit_image-0.19.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (13.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 13.3 MB 19.9 MB/s \n",
            "\u001b[?25h  Downloading scikit_image-0.19.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (55.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 55.4 MB 22 kB/s \n",
            "\u001b[?25h  Downloading scikit_image-0.18.2-cp37-cp37m-manylinux1_x86_64.whl (29.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 29.2 MB 1.3 MB/s \n",
            "\u001b[?25h  Downloading scikit_image-0.18.1-cp37-cp37m-manylinux1_x86_64.whl (29.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 29.2 MB 1.2 MB/s \n",
            "\u001b[?25h  Downloading scikit_image-0.18.0-cp37-cp37m-manylinux1_x86_64.whl (29.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 29.2 MB 1.2 MB/s \n",
            "\u001b[?25h  Downloading scikit_image-0.17.2-cp37-cp37m-manylinux1_x86_64.whl (12.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.5 MB 32.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.12->lime==0.2.0.1->-r requirements.txt (line 9)) (2.6.3)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.12->lime==0.2.0.1->-r requirements.txt (line 9)) (2021.11.2)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.12->lime==0.2.0.1->-r requirements.txt (line 9)) (1.3.0)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.12->lime==0.2.0.1->-r requirements.txt (line 9)) (2.9.0)\n",
            "Collecting PyWavelets>=1.1.1\n",
            "  Downloading PyWavelets-1.2.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (6.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.1 MB 31.2 MB/s \n",
            "\u001b[?25h  Downloading PyWavelets-1.1.1-cp37-cp37m-manylinux1_x86_64.whl (4.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.4 MB 57.2 MB/s \n",
            "\u001b[?25hCollecting anykeystore\n",
            "  Downloading anykeystore-0.2.tar.gz (10 kB)\n",
            "Collecting python3-openid\n",
            "  Downloading python3_openid-3.2.0-py3-none-any.whl (133 kB)\n",
            "\u001b[K     |████████████████████████████████| 133 kB 66.8 MB/s \n",
            "\u001b[?25hCollecting premailer\n",
            "  Downloading premailer-3.10.0-py2.py3-none-any.whl (19 kB)\n",
            "Collecting s3transfer<0.7.0,>=0.6.0\n",
            "  Downloading s3transfer-0.6.0-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 10.0 MB/s \n",
            "\u001b[?25hCollecting botocore<1.28.0,>=1.27.96\n",
            "  Downloading botocore-1.27.96-py3-none-any.whl (9.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 9.3 MB 49.6 MB/s \n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 72.8 MB/s \n",
            "\u001b[?25hCollecting simplejson\n",
            "  Downloading simplejson-3.17.6-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (130 kB)\n",
            "\u001b[K     |████████████████████████████████| 130 kB 58.4 MB/s \n",
            "\u001b[?25hCollecting bravado-core>=5.16.1\n",
            "  Downloading bravado_core-5.17.1-py2.py3-none-any.whl (67 kB)\n",
            "\u001b[K     |████████████████████████████████| 67 kB 6.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: msgpack in /usr/local/lib/python3.7/dist-packages (from bravado->neptune_client==0.4.107->-r requirements.txt (line 13)) (1.0.4)\n",
            "Collecting monotonic\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Requirement already satisfied: jsonschema[format]>=2.5.1 in /usr/local/lib/python3.7/dist-packages (from bravado-core>=5.16.1->bravado->neptune_client==0.4.107->-r requirements.txt (line 13)) (4.3.3)\n",
            "Collecting swagger-spec-validator>=2.0.1\n",
            "  Downloading swagger_spec_validator-3.0.2-py2.py3-none-any.whl (27 kB)\n",
            "Collecting jsonref\n",
            "  Downloading jsonref-0.3.0-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from jsonschema[format]>=2.5.1->bravado-core>=5.16.1->bravado->neptune_client==0.4.107->-r requirements.txt (line 13)) (4.13.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema[format]>=2.5.1->bravado-core>=5.16.1->bravado->neptune_client==0.4.107->-r requirements.txt (line 13)) (22.1.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema[format]>=2.5.1->bravado-core>=5.16.1->bravado->neptune_client==0.4.107->-r requirements.txt (line 13)) (0.18.1)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema[format]>=2.5.1->bravado-core>=5.16.1->bravado->neptune_client==0.4.107->-r requirements.txt (line 13)) (5.10.0)\n",
            "Collecting webcolors>=1.11\n",
            "  Downloading webcolors-1.12-py3-none-any.whl (9.9 kB)\n",
            "Collecting fqdn\n",
            "  Downloading fqdn-1.5.1-py3-none-any.whl (9.1 kB)\n",
            "Collecting rfc3339-validator\n",
            "  Downloading rfc3339_validator-0.1.4-py2.py3-none-any.whl (3.5 kB)\n",
            "Collecting isoduration\n",
            "  Downloading isoduration-20.11.0-py3-none-any.whl (11 kB)\n",
            "Collecting uri-template\n",
            "  Downloading uri_template-1.2.0-py3-none-any.whl (10 kB)\n",
            "Collecting jsonpointer>1.13\n",
            "  Downloading jsonpointer-2.3-py2.py3-none-any.whl (7.8 kB)\n",
            "Collecting rfc3987\n",
            "  Downloading rfc3987-1.3.8-py2.py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources>=1.4.0->jsonschema[format]>=2.5.1->bravado-core>=5.16.1->bravado->neptune_client==0.4.107->-r requirements.txt (line 13)) (3.9.0)\n",
            "Collecting pbkdf2\n",
            "  Downloading pbkdf2-1.3.tar.gz (6.4 kB)\n",
            "Requirement already satisfied: cached-property>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from fqdn->jsonschema[format]>=2.5.1->bravado-core>=5.16.1->bravado->neptune_client==0.4.107->-r requirements.txt (line 13)) (1.5.2)\n",
            "Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.7/dist-packages (from ftfy->ekphrasis==0.5.1->-r requirements.txt (line 6)) (0.2.5)\n",
            "Collecting arrow>=0.15.0\n",
            "  Downloading arrow-1.2.3-py3-none-any.whl (66 kB)\n",
            "\u001b[K     |████████████████████████████████| 66 kB 5.3 MB/s \n",
            "\u001b[?25hCollecting jeepney>=0.4.2\n",
            "  Downloading jeepney-0.8.0-py3-none-any.whl (48 kB)\n",
            "\u001b[K     |████████████████████████████████| 48 kB 6.0 MB/s \n",
            "\u001b[?25hCollecting jaraco.classes\n",
            "  Downloading jaraco.classes-3.2.3-py3-none-any.whl (6.0 kB)\n",
            "Collecting SecretStorage>=3.2\n",
            "  Downloading SecretStorage-3.3.3-py3-none-any.whl (15 kB)\n",
            "Collecting cryptography>=2.0\n",
            "  Downloading cryptography-38.0.1-cp36-abi3-manylinux_2_24_x86_64.whl (4.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 63.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=2.0->SecretStorage>=3.2->keyring->knockknock==0.1.7->-r requirements.txt (line 14)) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=2.0->SecretStorage>=3.2->keyring->knockknock==0.1.7->-r requirements.txt (line 14)) (2.21)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.7/dist-packages (from jaraco.classes->keyring->knockknock==0.1.7->-r requirements.txt (line 14)) (8.14.0)\n",
            "Collecting PasteDeploy>=2.0\n",
            "  Downloading PasteDeploy-3.0.1-py3-none-any.whl (16 kB)\n",
            "Collecting cssselect\n",
            "  Downloading cssselect-1.1.0-py2.py3-none-any.whl (16 kB)\n",
            "Collecting cssutils\n",
            "  Downloading cssutils-2.6.0-py3-none-any.whl (399 kB)\n",
            "\u001b[K     |████████████████████████████████| 399 kB 73.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cachetools in /usr/local/lib/python3.7/dist-packages (from premailer->yagmail>=0.11.214->knockknock==0.1.7->-r requirements.txt (line 14)) (4.2.4)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from premailer->yagmail>=0.11.214->knockknock==0.1.7->-r requirements.txt (line 14)) (4.9.1)\n",
            "Collecting xmltodict\n",
            "  Downloading xmltodict-0.13.0-py2.py3-none-any.whl (10.0 kB)\n",
            "Collecting transaction\n",
            "  Downloading transaction-3.0.1-py2.py3-none-any.whl (47 kB)\n",
            "\u001b[K     |████████████████████████████████| 47 kB 5.3 MB/s \n",
            "\u001b[?25hCollecting repoze.sendmail>=4.1\n",
            "  Downloading repoze.sendmail-4.4.1-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[K     |████████████████████████████████| 41 kB 44 kB/s \n",
            "\u001b[?25hCollecting APScheduler==3.6.3\n",
            "  Downloading APScheduler-3.6.3-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[K     |████████████████████████████████| 58 kB 6.6 MB/s \n",
            "\u001b[?25hCollecting cachetools\n",
            "  Downloading cachetools-4.2.2-py3-none-any.whl (11 kB)\n",
            "Collecting tornado==6.1\n",
            "  Downloading tornado-6.1-cp37-cp37m-manylinux2010_x86_64.whl (428 kB)\n",
            "\u001b[K     |████████████████████████████████| 428 kB 71.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tzlocal>=1.2 in /usr/local/lib/python3.7/dist-packages (from APScheduler==3.6.3->python-telegram-bot->knockknock==0.1.7->-r requirements.txt (line 14)) (1.5.1)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from python3-openid->velruse>=1.0.3->apex==0.9.10dev->-r requirements.txt (line 16)) (0.7.1)\n",
            "Requirement already satisfied: MarkupSafe in /usr/local/lib/python3.7/dist-packages (from wtforms->apex==0.9.10dev->-r requirements.txt (line 16)) (2.0.1)\n",
            "Requirement already satisfied: SQLAlchemy!=1.4.0,!=1.4.1,!=1.4.2,!=1.4.3,!=1.4.4,!=1.4.5,!=1.4.6,>=0.9 in /usr/local/lib/python3.7/dist-packages (from zope.sqlalchemy->apex==0.9.10dev->-r requirements.txt (line 16)) (1.4.41)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from SQLAlchemy!=1.4.0,!=1.4.1,!=1.4.2,!=1.4.3,!=1.4.4,!=1.4.5,!=1.4.6,>=0.9->zope.sqlalchemy->apex==0.9.10dev->-r requirements.txt (line 16)) (1.1.3.post0)\n",
            "Building wheels for collected packages: waiting, ekphrasis, lime, neptune-client, apex, GPUtil, future, velruse, anykeystore, cryptacular, pbkdf2, sacremoses\n",
            "  Building wheel for waiting (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for waiting: filename=waiting-1.4.1-py3-none-any.whl size=3761 sha256=3ab84fb289078b9976401319b8c7c72177c6c12d11809372ce15f40bcee857e6\n",
            "  Stored in directory: /root/.cache/pip/wheels/27/e5/bb/ee3da3e19f6bffa54131b5039cb25b5eca9e4981a248504840\n",
            "  Building wheel for ekphrasis (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ekphrasis: filename=ekphrasis-0.5.1-py3-none-any.whl size=82842 sha256=dac301c829eb275bdb8284fd7be69dcfb3b3f59b9851feb2af080ee8a44ec233\n",
            "  Stored in directory: /root/.cache/pip/wheels/f7/ec/0d/12659e32faf780546945d0120f2c8410eb3efb7426731da88f\n",
            "  Building wheel for lime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lime: filename=lime-0.2.0.1-py3-none-any.whl size=283857 sha256=937211eaff76d880fbcd6217d70b7753db69db96694958b575cf426f6ba8f177\n",
            "  Stored in directory: /root/.cache/pip/wheels/ca/cb/e5/ac701e12d365a08917bf4c6171c0961bc880a8181359c66aa7\n",
            "  Building wheel for neptune-client (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for neptune-client: filename=neptune_client-0.4.107-py2.py3-none-any.whl size=145062 sha256=649465453a579d60cc68c4418ba9a6825032cba4d973f527782647255ee43a8c\n",
            "  Stored in directory: /root/.cache/pip/wheels/7b/2b/f8/91012c0b3f7a4fe6a3907b274b69cac53bb9edacef63909f01\n",
            "  Building wheel for apex (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for apex: filename=apex-0.9.10.dev0-py3-none-any.whl size=46467 sha256=a6ea40fb1860a0a3f10a8b3075e36298093b019099a9f21ec48ddc528b1f8234\n",
            "  Stored in directory: /root/.cache/pip/wheels/f0/00/2b/37b6028388b451bbd30230c62f5238aef3b11fdff9503138bc\n",
            "  Building wheel for GPUtil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for GPUtil: filename=GPUtil-1.4.0-py3-none-any.whl size=7411 sha256=f8d8824fad756eee02e69745e5f32f2f74cae3a468cf1f48027c60296e4f907d\n",
            "  Stored in directory: /root/.cache/pip/wheels/6e/f8/83/534c52482d6da64622ddbf72cd93c35d2ef2881b78fd08ff0c\n",
            "  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491070 sha256=04d6c962518565bcb12b01b062261ee8ac11fcfc34429dd4c5f4cf6ab2574275\n",
            "  Stored in directory: /root/.cache/pip/wheels/56/b0/fe/4410d17b32f1f0c3cf54cdfb2bc04d7b4b8f4ae377e2229ba0\n",
            "  Building wheel for velruse (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for velruse: filename=velruse-1.1.1-py3-none-any.whl size=50938 sha256=3b57c3dc74246076b55cdea9c17fc359e2b2360a426f593cfbfd0e86095dd6dc\n",
            "  Stored in directory: /root/.cache/pip/wheels/61/f0/95/7f8b3bb1cce5c78ca7a7922cf72383f886f70e358f0a18d60b\n",
            "  Building wheel for anykeystore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for anykeystore: filename=anykeystore-0.2-py3-none-any.whl size=17043 sha256=8442cb07ebff9b856ec28b6a88e8e7f0545f9d64e6b248f4768f3fffbf673cdd\n",
            "  Stored in directory: /root/.cache/pip/wheels/12/14/12/afad2dc2b7ea0884e12f260b0723b49b98f39f08adb7b0414f\n",
            "  Building wheel for cryptacular (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cryptacular: filename=cryptacular-1.6.2-cp37-cp37m-linux_x86_64.whl size=54544 sha256=dbdda0b30cd75d47a292a6a0ac89e32e113032f431c6a05af4cbaa967fc72122\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/e8/c2/4b71f45f434136d31df930960b8a916bb36ebe2144479a37a1\n",
            "  Building wheel for pbkdf2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pbkdf2: filename=pbkdf2-1.3-py3-none-any.whl size=5105 sha256=ef6aabb149c1a98eaef06376377f79ddc2940b9e020e753044da0af3763a9afd\n",
            "  Stored in directory: /root/.cache/pip/wheels/49/16/ea/daca297d70ee0782ac6e16e83b2c55b2ca42a2113750bc0489\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=d14d762204b0d1f98d3953b2c16cab1d52cfb15b4f0e19f724ab89c28ea603f8\n",
            "  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n",
            "Successfully built waiting ekphrasis lime neptune-client apex GPUtil future velruse anykeystore cryptacular pbkdf2 sacremoses\n",
            "Installing collected packages: arrow, zope.interface, webcolors, urllib3, uri-template, rfc3987, rfc3339-validator, plaster, PasteDeploy, jsonpointer, jmespath, isoduration, fqdn, zope.deprecation, webob, venusian, translationstring, transaction, swagger-spec-validator, smmap, simplejson, plaster-pastedeploy, numpy, jsonref, jeepney, hupper, cssutils, cssselect, cryptography, cachetools, botocore, xmltodict, wtforms, tqdm, tornado, SecretStorage, scipy, s3transfer, repoze.sendmail, PyWavelets, python3-openid, pyramid, PyJWT, premailer, pbkdf2, monotonic, matplotlib, jaraco.classes, gitdb, bravado-core, APScheduler, anykeystore, zope.sqlalchemy, yagmail, wtforms-recaptcha, websocket-client, velruse, twilio, tokenizers, sentencepiece, scikit-learn, scikit-image, sacremoses, python-telegram-bot, pyramid-mailer, py3nvml, pandas, matrix-client, keyring, keras-applications, GitPython, future, ftfy, cryptacular, colorama, bravado, boto3, waiting, transformers, torch, neptune-client, lime, knockknock, Keras, GPUtil, gensim, ekphrasis, dataclasses, apex\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.21.6\n",
            "    Uninstalling numpy-1.21.6:\n",
            "      Successfully uninstalled numpy-1.21.6\n",
            "  Attempting uninstall: cachetools\n",
            "    Found existing installation: cachetools 4.2.4\n",
            "    Uninstalling cachetools-4.2.4:\n",
            "      Successfully uninstalled cachetools-4.2.4\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.64.1\n",
            "    Uninstalling tqdm-4.64.1:\n",
            "      Successfully uninstalled tqdm-4.64.1\n",
            "  Attempting uninstall: tornado\n",
            "    Found existing installation: tornado 5.1.1\n",
            "    Uninstalling tornado-5.1.1:\n",
            "      Successfully uninstalled tornado-5.1.1\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.7.3\n",
            "    Uninstalling scipy-1.7.3:\n",
            "      Successfully uninstalled scipy-1.7.3\n",
            "  Attempting uninstall: PyWavelets\n",
            "    Found existing installation: PyWavelets 1.3.0\n",
            "    Uninstalling PyWavelets-1.3.0:\n",
            "      Successfully uninstalled PyWavelets-1.3.0\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.2.2\n",
            "    Uninstalling matplotlib-3.2.2:\n",
            "      Successfully uninstalled matplotlib-3.2.2\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.0.2\n",
            "    Uninstalling scikit-learn-1.0.2:\n",
            "      Successfully uninstalled scikit-learn-1.0.2\n",
            "  Attempting uninstall: scikit-image\n",
            "    Found existing installation: scikit-image 0.18.3\n",
            "    Uninstalling scikit-image-0.18.3:\n",
            "      Successfully uninstalled scikit-image-0.18.3\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 1.3.5\n",
            "    Uninstalling pandas-1.3.5:\n",
            "      Successfully uninstalled pandas-1.3.5\n",
            "  Attempting uninstall: future\n",
            "    Found existing installation: future 0.16.0\n",
            "    Uninstalling future-0.16.0:\n",
            "      Successfully uninstalled future-0.16.0\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.12.1+cu113\n",
            "    Uninstalling torch-1.12.1+cu113:\n",
            "      Successfully uninstalled torch-1.12.1+cu113\n",
            "  Attempting uninstall: Keras\n",
            "    Found existing installation: keras 2.8.0\n",
            "    Uninstalling keras-2.8.0:\n",
            "      Successfully uninstalled keras-2.8.0\n",
            "  Attempting uninstall: gensim\n",
            "    Found existing installation: gensim 3.6.0\n",
            "    Uninstalling gensim-3.6.0:\n",
            "      Successfully uninstalled gensim-3.6.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "yellowbrick 1.5 requires scikit-learn>=1.0.0, but you have scikit-learn 0.23.2 which is incompatible.\n",
            "xarray 0.20.2 requires numpy>=1.18, but you have numpy 1.16.3 which is incompatible.\n",
            "xarray 0.20.2 requires pandas>=1.1, but you have pandas 1.0.3 which is incompatible.\n",
            "xarray-einstats 0.2.2 requires numpy>=1.21, but you have numpy 1.16.3 which is incompatible.\n",
            "torchvision 0.13.1+cu113 requires torch==1.12.1, but you have torch 1.1.0 which is incompatible.\n",
            "torchtext 0.13.1 requires torch==1.12.1, but you have torch 1.1.0 which is incompatible.\n",
            "torchaudio 0.12.1+cu113 requires torch==1.12.1, but you have torch 1.1.0 which is incompatible.\n",
            "tensorflow 2.8.0+zzzcolab20220506162203 requires keras<2.9,>=2.8.0rc0, but you have keras 2.3.1 which is incompatible.\n",
            "tensorflow 2.8.0+zzzcolab20220506162203 requires numpy>=1.20, but you have numpy 1.16.3 which is incompatible.\n",
            "tables 3.7.0 requires numpy>=1.19.0, but you have numpy 1.16.3 which is incompatible.\n",
            "resampy 0.4.2 requires numpy>=1.17, but you have numpy 1.16.3 which is incompatible.\n",
            "pyerfa 2.0.0.1 requires numpy>=1.17, but you have numpy 1.16.3 which is incompatible.\n",
            "pyarrow 6.0.1 requires numpy>=1.16.6, but you have numpy 1.16.3 which is incompatible.\n",
            "prophet 1.1.1 requires pandas>=1.0.4, but you have pandas 1.0.3 which is incompatible.\n",
            "plotnine 0.8.0 requires numpy>=1.19.0, but you have numpy 1.16.3 which is incompatible.\n",
            "plotnine 0.8.0 requires pandas>=1.1.0, but you have pandas 1.0.3 which is incompatible.\n",
            "plotnine 0.8.0 requires scipy>=1.5.0, but you have scipy 1.4.1 which is incompatible.\n",
            "panel 0.12.1 requires tqdm>=4.48.0, but you have tqdm 4.43.0 which is incompatible.\n",
            "numba 0.56.3 requires numpy<1.24,>=1.18, but you have numpy 1.16.3 which is incompatible.\n",
            "mizani 0.7.3 requires pandas>=1.1.0, but you have pandas 1.0.3 which is incompatible.\n",
            "kapre 0.3.7 requires numpy>=1.18.5, but you have numpy 1.16.3 which is incompatible.\n",
            "jaxlib 0.3.22+cuda11.cudnn805 requires numpy>=1.20, but you have numpy 1.16.3 which is incompatible.\n",
            "jaxlib 0.3.22+cuda11.cudnn805 requires scipy>=1.5, but you have scipy 1.4.1 which is incompatible.\n",
            "jax 0.3.23 requires numpy>=1.20, but you have numpy 1.16.3 which is incompatible.\n",
            "jax 0.3.23 requires scipy>=1.5, but you have scipy 1.4.1 which is incompatible.\n",
            "imbalanced-learn 0.8.1 requires scikit-learn>=0.24, but you have scikit-learn 0.23.2 which is incompatible.\n",
            "gym 0.25.2 requires numpy>=1.18.0, but you have numpy 1.16.3 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas>=1.1.0, but you have pandas 1.0.3 which is incompatible.\n",
            "google-colab 1.0.0 requires tornado~=5.1.0, but you have tornado 6.1 which is incompatible.\n",
            "fastai 2.7.9 requires torch<1.14,>=1.7, but you have torch 1.1.0 which is incompatible.\n",
            "cupy-cuda11x 11.0.0 requires numpy<1.26,>=1.20, but you have numpy 1.16.3 which is incompatible.\n",
            "cmdstanpy 1.0.7 requires numpy>=1.21, but you have numpy 1.16.3 which is incompatible.\n",
            "astropy 4.3.1 requires numpy>=1.17, but you have numpy 1.16.3 which is incompatible.\n",
            "aesara 2.7.9 requires numpy>=1.17.0, but you have numpy 1.16.3 which is incompatible.\n",
            "aeppl 0.0.33 requires numpy>=1.18.1, but you have numpy 1.16.3 which is incompatible.\u001b[0m\n",
            "Successfully installed APScheduler-3.6.3 GPUtil-1.4.0 GitPython-3.1.29 Keras-2.3.1 PasteDeploy-3.0.1 PyJWT-2.6.0 PyWavelets-1.1.1 SecretStorage-3.3.3 anykeystore-0.2 apex-0.9.10.dev0 arrow-1.2.3 boto3-1.24.96 botocore-1.27.96 bravado-11.0.3 bravado-core-5.17.1 cachetools-4.2.2 colorama-0.4.5 cryptacular-1.6.2 cryptography-38.0.1 cssselect-1.1.0 cssutils-2.6.0 dataclasses-0.6 ekphrasis-0.5.1 fqdn-1.5.1 ftfy-6.1.1 future-0.18.2 gensim-3.8.1 gitdb-4.0.9 hupper-1.10.3 isoduration-20.11.0 jaraco.classes-3.2.3 jeepney-0.8.0 jmespath-1.0.1 jsonpointer-2.3 jsonref-0.3.0 keras-applications-1.0.8 keyring-23.9.3 knockknock-0.1.7 lime-0.2.0.1 matplotlib-3.2.1 matrix-client-0.4.0 monotonic-1.6 neptune-client-0.4.107 numpy-1.16.3 pandas-1.0.3 pbkdf2-1.3 plaster-1.0 plaster-pastedeploy-0.7 premailer-3.10.0 py3nvml-0.2.7 pyramid-2.0 pyramid-mailer-0.15.1 python-telegram-bot-13.14 python3-openid-3.2.0 repoze.sendmail-4.4.1 rfc3339-validator-0.1.4 rfc3987-1.3.8 s3transfer-0.6.0 sacremoses-0.0.53 scikit-image-0.17.2 scikit-learn-0.23.2 scipy-1.4.1 sentencepiece-0.1.97 simplejson-3.17.6 smmap-5.0.0 swagger-spec-validator-3.0.2 tokenizers-0.5.2 torch-1.1.0 tornado-6.1 tqdm-4.43.0 transaction-3.0.1 transformers-2.5.1 translationstring-1.4 twilio-7.15.0 uri-template-1.2.0 urllib3-1.25.11 velruse-1.1.1 venusian-3.0.0 waiting-1.4.1 webcolors-1.12 webob-1.8.7 websocket-client-1.4.1 wtforms-3.0.1 wtforms-recaptcha-0.3.2 xmltodict-0.13.0 yagmail-0.15.293 zope.deprecation-4.4.0 zope.interface-5.5.0 zope.sqlalchemy-1.6\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "matplotlib",
                  "mpl_toolkits",
                  "numpy",
                  "tornado"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D5Hqb1OvsXDR",
        "outputId": "b5ad3c83-cba7-4535-a913-e8a8a94795ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.7/dist-packages (3.4.1)\n",
            "Collecting spacy\n",
            "  Downloading spacy-3.4.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.4 MB 34.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.10.1)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (8.1.4)\n",
            "Requirement already satisfied: typing-extensions<4.2.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.1.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.6.2)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.21.6)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.3.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (21.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy) (57.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.64.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.11.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.4.4)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.7)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.9.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.23.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.10)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.3)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.8)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.4.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy) (3.9.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy) (3.0.9)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy) (5.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.7/dist-packages (from thinc<8.2.0,>=8.1.0->spacy) (0.7.8)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.7/dist-packages (from thinc<8.2.0,>=8.1.0->spacy) (0.0.3)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy) (2.0.1)\n",
            "Installing collected packages: spacy\n",
            "  Attempting uninstall: spacy\n",
            "    Found existing installation: spacy 3.4.1\n",
            "    Uninstalling spacy-3.4.1:\n",
            "      Successfully uninstalled spacy-3.4.1\n",
            "Successfully installed spacy-3.4.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting keras==2.8\n",
            "  Downloading keras-2.8.0-py2.py3-none-any.whl (1.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4 MB 30.2 MB/s \n",
            "\u001b[?25hInstalling collected packages: keras\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.9.0\n",
            "    Uninstalling keras-2.9.0:\n",
            "      Successfully uninstalled keras-2.9.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.9.2 requires keras<2.10.0,>=2.9.0rc0, but you have keras 2.8.0 which is incompatible.\u001b[0m\n",
            "Successfully installed keras-2.8.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow==2.8\n",
            "  Downloading https://us-python.pkg.dev/colab-wheels/public/tensorflow/tensorflow-2.8.0%2Bzzzcolab20220506162203-cp37-cp37m-linux_x86_64.whl (668.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 668.3 MB 17 kB/s \n",
            "\u001b[?25hCollecting tf-estimator-nightly==2.8.0.dev2021122109\n",
            "  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[K     |████████████████████████████████| 462 kB 39.6 MB/s \n",
            "\u001b[?25hCollecting tensorboard<2.9,>=2.8\n",
            "  Downloading tensorboard-2.8.0-py3-none-any.whl (5.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 4.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (2.0.1)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (3.17.3)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (1.6.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (57.4.0)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (2.8.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (1.3.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (14.0.6)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (0.27.0)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (0.4.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (1.15.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (3.3.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (3.1.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (1.49.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (0.2.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (1.1.2)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (4.1.1)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (1.21.6)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8) (1.12)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow==2.8) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow==2.8) (1.5.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8) (1.0.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8) (1.35.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8) (1.8.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8) (3.4.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8) (4.9)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow==2.8) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow==2.8) (4.13.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow==2.8) (3.9.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow==2.8) (3.2.1)\n",
            "Installing collected packages: tf-estimator-nightly, tensorboard, tensorflow\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.9.1\n",
            "    Uninstalling tensorboard-2.9.1:\n",
            "      Successfully uninstalled tensorboard-2.9.1\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.9.2\n",
            "    Uninstalling tensorflow-2.9.2:\n",
            "      Successfully uninstalled tensorflow-2.9.2\n",
            "Successfully installed tensorboard-2.8.0 tensorflow-2.8.0+zzzcolab20220506162203 tf-estimator-nightly-2.8.0.dev2021122109\n"
          ]
        }
      ],
      "source": [
        "!pip install -U spacy\n",
        "! pip install keras==2.8\n",
        "!pip install tensorflow==2.8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nlq-y7f7nxdP"
      },
      "outputs": [],
      "source": [
        "from gensim.models import KeyedVectors\n",
        "from gensim.test.utils import get_tmpfile\n",
        "from gensim.scripts.glove2word2vec import glove2word2vec\n",
        "glove2word2vec('Data/glove.42B.300d.txt', 'Data/glove.42B.300d_w2v.txt')\n",
        "word2vecmodel1 = KeyedVectors.load_word2vec_format('Data/glove.42B.300d_w2v.txt', binary=False)\n",
        "word2vecmodel1.save(\"Data/word2vec.model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KrVyCVHdlWSc",
        "outputId": "942fb033-0e26-43b1-9b49-0f3f0f97ab99"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "236"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "import gc\n",
        "del word2vecmodel1\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5HS3NNHzmX64"
      },
      "outputs": [],
      "source": [
        "!rm Data/glove.42B.300d.txt\n",
        "!rm Data/glove.42B.300d_w2v.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d42eb43d-d07e-47c6-c925-6fb163e25911",
        "id": "IsdoE3Y1jiUH"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word statistics files not found!\n",
            "Downloading... done!\n",
            "Unpacking... done!\n",
            "Reading twitter - 1grams ...\n",
            "generating cache file for faster loading...\n",
            "reading ngrams /root/.ekphrasis/stats/twitter/counts_1grams.txt\n",
            "Reading twitter - 2grams ...\n",
            "generating cache file for faster loading...\n",
            "reading ngrams /root/.ekphrasis/stats/twitter/counts_2grams.txt\n",
            "Reading english - 1grams ...\n",
            "generating cache file for faster loading...\n",
            "reading ngrams /root/.ekphrasis/stats/english/counts_1grams.txt\n"
          ]
        }
      ],
      "source": [
        "from manual_training_inference import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MIKH2h5hzwcT",
        "outputId": "7528c54b-8ea9-4b5a-c73d-c355a0c49799"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Since you dont want to use GPU, using the CPU instead.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 64/20148 [00:00<00:31, 631.34it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total_data 20148\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20148/20148 [00:32<00:00, 615.32it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attention_error: 0\n",
            "no_majority: 919\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 10%|▉         | 1494/15383 [00:00<00:01, 7436.53it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "unk\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 15383/15383 [00:02<00:00, 7123.13it/s]\n",
            "  6%|▌         | 880/15383 [00:00<00:01, 8795.10it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(22236, 300)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 15383/15383 [00:02<00:00, 5913.22it/s]\n",
            "100%|██████████| 1922/1922 [00:00<00:00, 8119.27it/s]\n",
            "100%|██████████| 1924/1924 [00:00<00:00, 8314.66it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total dataset size: 19229\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:70: FutureWarning: Pass classes=['non-toxic' 'toxic'], y=['non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic'] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
            "  FutureWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1.2301791 0.8423818]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:54: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n",
            "\r0it [00:00, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 5 ========\n",
            "Training...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "481it [02:50,  2.83it/s]\n",
            "2it [00:00, 13.22it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "avg_train_loss 295.31263076242936\n",
            "model previously passed\n",
            "Running eval on  train ...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "481it [00:33, 14.19it/s]\n",
            "2it [00:00, 13.01it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Accuracy: 0.69\n",
            " Fscore: 0.68\n",
            " Precision: 0.74\n",
            " Recall: 0.72\n",
            " Roc Auc: 0.00\n",
            " Test took: 0:00:34\n",
            "model previously passed\n",
            "Running eval on  val ...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "61it [00:04, 14.37it/s]\n",
            "2it [00:00, 13.37it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Accuracy: 0.65\n",
            " Fscore: 0.65\n",
            " Precision: 0.71\n",
            " Recall: 0.69\n",
            " Roc Auc: 0.00\n",
            " Test took: 0:00:04\n",
            "model previously passed\n",
            "Running eval on  test ...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "61it [00:04, 14.33it/s]\n",
            "0it [00:00, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Accuracy: 0.66\n",
            " Fscore: 0.66\n",
            " Precision: 0.72\n",
            " Recall: 0.70\n",
            " Roc Auc: 0.00\n",
            " Test took: 0:00:04\n",
            "0.646751680033857 0\n",
            "Saving model\n",
            "Saved/birnnscrat_lstm_64_2_100.pth\n",
            "\n",
            "======== Epoch 2 / 5 ========\n",
            "Training...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "481it [03:00,  2.67it/s]\n",
            "2it [00:00, 13.89it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "avg_train_loss 295.1592615964259\n",
            "model previously passed\n",
            "Running eval on  train ...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "481it [00:34, 14.13it/s]\n",
            "2it [00:00, 13.31it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Accuracy: 0.73\n",
            " Fscore: 0.73\n",
            " Precision: 0.77\n",
            " Recall: 0.76\n",
            " Roc Auc: 0.00\n",
            " Test took: 0:00:34\n",
            "model previously passed\n",
            "Running eval on  val ...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "61it [00:04, 14.54it/s]\n",
            "2it [00:00, 14.17it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Accuracy: 0.68\n",
            " Fscore: 0.68\n",
            " Precision: 0.73\n",
            " Recall: 0.72\n",
            " Roc Auc: 0.00\n",
            " Test took: 0:00:04\n",
            "model previously passed\n",
            "Running eval on  test ...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "61it [00:04, 14.50it/s]\n",
            "0it [00:00, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Accuracy: 0.69\n",
            " Fscore: 0.69\n",
            " Precision: 0.73\n",
            " Recall: 0.72\n",
            " Roc Auc: 0.00\n",
            " Test took: 0:00:04\n",
            "0.6832377651294752 0.646751680033857\n",
            "Saving model\n",
            "Saved/birnnscrat_lstm_64_2_100.pth\n",
            "\n",
            "======== Epoch 3 / 5 ========\n",
            "Training...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "481it [03:19,  2.41it/s]\n",
            "2it [00:00, 13.13it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "avg_train_loss 295.07895563645076\n",
            "model previously passed\n",
            "Running eval on  train ...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "481it [00:33, 14.18it/s]\n",
            "2it [00:00, 14.56it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Accuracy: 0.79\n",
            " Fscore: 0.79\n",
            " Precision: 0.81\n",
            " Recall: 0.81\n",
            " Roc Auc: 0.00\n",
            " Test took: 0:00:34\n",
            "model previously passed\n",
            "Running eval on  val ...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "61it [00:04, 14.37it/s]\n",
            "2it [00:00, 13.72it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Accuracy: 0.70\n",
            " Fscore: 0.70\n",
            " Precision: 0.73\n",
            " Recall: 0.73\n",
            " Roc Auc: 0.00\n",
            " Test took: 0:00:04\n",
            "model previously passed\n",
            "Running eval on  test ...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "61it [00:04, 14.34it/s]\n",
            "0it [00:00, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Accuracy: 0.70\n",
            " Fscore: 0.70\n",
            " Precision: 0.73\n",
            " Recall: 0.73\n",
            " Roc Auc: 0.00\n",
            " Test took: 0:00:04\n",
            "0.6981002490464414 0.6832377651294752\n",
            "Saving model\n",
            "Saved/birnnscrat_lstm_64_2_100.pth\n",
            "\n",
            "======== Epoch 4 / 5 ========\n",
            "Training...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "481it [03:23,  2.37it/s]\n",
            "2it [00:00, 14.62it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "avg_train_loss 295.03012116683993\n",
            "model previously passed\n",
            "Running eval on  train ...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "481it [00:32, 14.71it/s]\n",
            "2it [00:00, 14.03it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Accuracy: 0.83\n",
            " Fscore: 0.83\n",
            " Precision: 0.84\n",
            " Recall: 0.85\n",
            " Roc Auc: 0.00\n",
            " Test took: 0:00:33\n",
            "model previously passed\n",
            "Running eval on  val ...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "61it [00:04, 14.84it/s]\n",
            "2it [00:00, 14.51it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Accuracy: 0.69\n",
            " Fscore: 0.69\n",
            " Precision: 0.72\n",
            " Recall: 0.72\n",
            " Roc Auc: 0.00\n",
            " Test took: 0:00:04\n",
            "model previously passed\n",
            "Running eval on  test ...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "61it [00:04, 14.94it/s]\n",
            "0it [00:00, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Accuracy: 0.69\n",
            " Fscore: 0.69\n",
            " Precision: 0.72\n",
            " Recall: 0.72\n",
            " Roc Auc: 0.00\n",
            " Test took: 0:00:04\n",
            "\n",
            "======== Epoch 5 / 5 ========\n",
            "Training...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "481it [03:27,  2.32it/s]\n",
            "2it [00:00, 14.59it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "avg_train_loss 294.9739048059666\n",
            "model previously passed\n",
            "Running eval on  train ...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "481it [00:32, 14.60it/s]\n",
            "2it [00:00, 14.29it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Accuracy: 0.85\n",
            " Fscore: 0.85\n",
            " Precision: 0.86\n",
            " Recall: 0.87\n",
            " Roc Auc: 0.00\n",
            " Test took: 0:00:33\n",
            "model previously passed\n",
            "Running eval on  val ...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "61it [00:04, 14.84it/s]\n",
            "2it [00:00, 15.28it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Accuracy: 0.69\n",
            " Fscore: 0.69\n",
            " Precision: 0.71\n",
            " Recall: 0.71\n",
            " Roc Auc: 0.00\n",
            " Test took: 0:00:04\n",
            "model previously passed\n",
            "Running eval on  test ...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "61it [00:04, 14.68it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Accuracy: 0.68\n",
            " Fscore: 0.68\n",
            " Precision: 0.70\n",
            " Recall: 0.71\n",
            " Roc Auc: 0.00\n",
            " Test took: 0:00:04\n",
            "best_val_fscore 0.6981002490464414\n",
            "best_test_fscore 0.697965467609571\n",
            "best_val_rocauc 0\n",
            "best_test_rocauc 0\n",
            "best_val_precision 0.73181994261365\n",
            "best_test_precision 0.7287470470600899\n",
            "best_val_recall 0.7276576357195039\n",
            "best_test_recall 0.7260706079431697\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "path_file='best_model_json/bestModel_birnnscrat.json'\n",
        "with open(path_file,mode='r') as f:\n",
        "    params = json.load(f)\n",
        "for key in params:\n",
        "    if params[key] == 'True':\n",
        "          params[key]=True\n",
        "    elif params[key] == 'False':\n",
        "          params[key]=False\n",
        "    if( key in ['batch_size','num_classes','hidden_size','supervised_layer_pos','num_supervised_heads','random_seed','max_length']):\n",
        "        if(params[key]!='N/A'):\n",
        "            params[key]=int(params[key])\n",
        "        \n",
        "    if((key == 'weights') and (params['auto_weights']==False)):\n",
        "        params[key] = ast.literal_eval(params[key])\n",
        "\n",
        "##### change in logging to output the results to neptune\n",
        "params['logging']='local'\n",
        "params['device']='cpu'\n",
        "params['best_params']=False\n",
        "\n",
        "if torch.cuda.is_available() and params['device']=='cuda':    \n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    print('Since you dont want to use GPU, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")\n",
        "    \n",
        "    \n",
        "#### Few handy keys that you can directly change.\n",
        "params['variance']=1\n",
        "params['epochs']=5\n",
        "params['to_save']=True\n",
        "params['num_classes']=2\n",
        "params['data_file']=dict_data_folder[str(params['num_classes'])]['data_file']\n",
        "params['class_names']=dict_data_folder[str(params['num_classes'])]['class_label']\n",
        "if(params['num_classes']==2 and (params['auto_weights']==False)):\n",
        "      params['weights']=[1.0,1.0]\n",
        "        \n",
        "#for att_lambda in [0.001,0.01,0.1,1,10,100]\n",
        "train_model(params,device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ORBj47ArF8-F",
        "outputId": "567d4781-91f1-4bd0-d0e5-42dff81b34ae"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  9%|▉         | 1404/15383 [00:00<00:01, 7061.43it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "unk\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 15383/15383 [00:02<00:00, 7098.62it/s]\n",
            "  5%|▌         | 792/15383 [00:00<00:01, 7911.14it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(22236, 300)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 15383/15383 [00:01<00:00, 8145.09it/s]\n",
            "100%|██████████| 1922/1922 [00:00<00:00, 7989.14it/s]\n",
            "100%|██████████| 1924/1924 [00:00<00:00, 8321.53it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total dataset size: 19229\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:70: FutureWarning: Pass classes=['hatespeech' 'normal' 'offensive'], y=['normal', 'hatespeech', 'normal', 'normal', 'offensive', 'normal', 'normal', 'hatespeech', 'normal', 'offensive', 'hatespeech', 'normal', 'normal', 'offensive', 'hatespeech', 'normal', 'normal', 'normal', 'normal', 'offensive', 'offensive', 'offensive', 'normal', 'offensive', 'hatespeech', 'hatespeech', 'hatespeech', 'normal', 'hatespeech', 'hatespeech', 'normal', 'offensive', 'normal', 'hatespeech', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'hatespeech', 'normal', 'normal', 'hatespeech', 'normal', 'normal', 'hatespeech', 'offensive', 'offensive', 'hatespeech', 'normal', 'hatespeech', 'hatespeech', 'normal', 'offensive', 'hatespeech', 'hatespeech', 'normal', 'offensive', 'offensive', 'hatespeech', 'normal', 'hatespeech', 'normal', 'normal', 'hatespeech', 'normal', 'hatespeech', 'hatespeech', 'offensive', 'hatespeech', 'normal', 'normal', 'hatespeech', 'normal', 'hatespeech', 'normal', 'hatespeech', 'hatespeech', 'offensive', 'normal', 'normal', 'hatespeech', 'hatespeech', 'offensive', 'normal', 'hatespeech', 'normal', 'hatespeech', 'hatespeech', 'normal', 'normal', 'normal', 'normal', 'hatespeech', 'normal', 'normal', 'normal', 'normal', 'hatespeech', 'hatespeech', 'hatespeech', 'hatespeech', 'normal', 'hatespeech', 'normal', 'hatespeech', 'normal', 'hatespeech', 'hatespeech', 'hatespeech', 'hatespeech', 'hatespeech', 'normal', 'normal', 'normal', 'offensive', 'hatespeech', 'normal', 'normal', 'normal', 'hatespeech', 'hatespeech', 'normal', 'normal', 'normal', 'normal', 'normal', 'hatespeech', 'hatespeech', 'hatespeech', 'hatespeech', 'normal', 'normal', 'normal', 'offensive', 'offensive', 'normal', 'hatespeech', 'hatespeech', 'hatespeech', 'normal', 'normal', 'offensive', 'hatespeech', 'normal', 'hatespeech', 'offensive', 'hatespeech', 'normal', 'normal', 'hatespeech', 'normal', 'hatespeech', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'hatespeech', 'normal', 'hatespeech', 'hatespeech', 'normal', 'hatespeech', 'offensive', 'normal', 'hatespeech', 'offensive', 'hatespeech', 'offensive', 'normal', 'normal', 'normal', 'hatespeech', 'hatespeech', 'hatespeech', 'hatespeech', 'hatespeech', 'hatespeech', 'hatespeech', 'hatespeech', 'normal', 'hatespeech', 'normal', 'hatespeech', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'hatespeech', 'hatespeech', 'offensive', 'offensive', 'normal', 'offensive', 'hatespeech', 'normal', 'normal', 'hatespeech', 'hatespeech', 'normal', 'hatespeech', 'normal', 'offensive', 'normal', 'offensive', 'normal', 'normal', 'hatespeech', 'hatespeech', 'hatespeech', 'hatespeech', 'normal', 'normal', 'normal', 'normal', 'offensive', 'hatespeech', 'normal', 'hatespeech', 'normal', 'offensive', 'normal', 'normal', 'normal', 'normal', 'hatespeech', 'hatespeech', 'hatespeech', 'normal', 'normal', 'normal', 'normal', 'offensive', 'offensive', 'normal', 'normal', 'hatespeech', 'hatespeech', 'normal', 'hatespeech', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'offensive', 'hatespeech', 'normal', 'hatespeech', 'normal', 'hatespeech', 'normal', 'hatespeech', 'offensive', 'normal', 'hatespeech', 'hatespeech', 'normal', 'offensive', 'normal', 'hatespeech', 'hatespeech', 'normal', 'hatespeech', 'normal', 'normal', 'normal', 'hatespeech', 'hatespeech', 'hatespeech', 'normal', 'hatespeech', 'normal', 'hatespeech', 'hatespeech', 'normal', 'offensive', 'hatespeech', 'normal', 'normal', 'hatespeech', 'hatespeech', 'hatespeech', 'hatespeech', 'hatespeech', 'hatespeech', 'hatespeech', 'normal', 'hatespeech', 'normal', 'normal', 'normal', 'offensive', 'normal', 'offensive', 'normal', 'normal', 'normal', 'normal', 'hatespeech', 'hatespeech', 'hatespeech', 'hatespeech', 'hatespeech', 'hatespeech', 'normal', 'hatespeech', 'hatespeech', 'hatespeech', 'hatespeech', 'hatespeech', 'normal', 'offensive', 'normal', 'hatespeech', 'hatespeech', 'normal', 'hatespeech', 'hatespeech', 'hatespeech', 'hatespeech', 'hatespeech', 'normal', 'hatespeech', 'hatespeech', 'normal', 'offensive', 'normal', 'normal', 'offensive', 'hatespeech', 'normal', 'normal', 'offensive', 'offensive', 'hatespeech', 'offensive', 'normal', 'offensive', 'hatespeech', 'normal', 'offensive', 'normal', 'hatespeech', 'normal', 'normal', 'normal', 'hatespeech', 'hatespeech', 'offensive', 'normal', 'hatespeech', 'normal', 'normal', 'normal', 'hatespeech', 'hatespeech', 'hatespeech', 'hatespeech', 'hatespeech', 'normal', 'offensive', 'hatespeech', 'normal', 'hatespeech', 'offensive', 'normal', 'hatespeech', 'normal', 'normal', 'normal', 'offensive', 'hatespeech', 'hatespeech', 'normal', 'hatespeech', 'normal', 'normal', 'hatespeech', 'hatespeech', 'normal', 'offensive', 'hatespeech', 'hatespeech', 'normal', 'hatespeech', 'hatespeech', 'hatespeech', 'hatespeech', 'normal', 'offensive', 'normal', 'hatespeech', 'offensive', 'hatespeech', 'hatespeech', 'hatespeech', 'hatespeech', 'hatespeech', 'hatespeech', 'normal', 'hatespeech', 'hatespeech', 'hatespeech', 'hatespeech', 'hatespeech', 'normal', 'normal', 'offensive', 'hatespeech', 'normal', 'normal', 'hatespeech', 'hatespeech', 'hatespeech', 'hatespeech', 'normal', 'offensive', 'hatespeech', 'normal', 'normal', 'normal', 'offensive', 'hatespeech', 'hatespeech', 'normal', 'offensive', 'offensive', 'hatespeech', 'normal', 'normal', 'normal', 'normal', 'normal', 'offensive', 'hatespeech', 'hatespeech', 'offensive', 'hatespeech', 'offensive', 'normal', 'normal', 'hatespeech', 'offensive', 'hatespeech', 'normal', 'offensive', 'normal', 'hatespeech', 'normal', 'normal', 'normal', 'offensive', 'offensive', 'normal', 'hatespeech', 'hatespeech', 'hatespeech', 'normal', 'normal', 'hatespeech', 'hatespeech', 'hatespeech', 'hatespeech', 'hatespeech', 'hatespeech', 'hatespeech', 'normal', 'hatespeech', 'normal', 'normal', 'normal', 'normal', 'normal', 'offensive', 'offensive', 'offensive', 'normal', 'offensive', 'hatespeech', 'normal', 'hatespeech', 'offensive', 'normal', 'hatespeech', 'hatespeech', 'normal', 'hatespeech', 'hatespeech', 'hatespeech', 'offensive', 'normal', 'normal', 'hatespeech', 'normal', 'hatespeech', 'hatespeech', 'hatespeech', 'offensive', 'normal', 'normal', 'normal', 'offensive', 'normal', 'normal', 'hatespeech', 'normal', 'hatespeech', 'normal', 'normal', 'normal', 'hatespeech', 'hatespeech', 'normal', 'normal', 'hatespeech', 'normal', 'hatespeech', 'normal', 'normal', 'normal', 'offensive', 'hatespeech', 'hatespeech', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'hatespeech', 'offensive', 'hatespeech', 'hatespeech', 'hatespeech', 'normal', 'hatespeech', 'normal', 'hatespeech', 'normal', 'normal', 'offensive', 'hatespeech', 'normal', 'normal', 'hatespeech', 'normal', 'offensive', 'normal', 'normal', 'hatespeech', 'offensive', 'normal', 'normal', 'offensive', 'hatespeech', 'normal', 'offensive', 'hatespeech', 'normal', 'normal', 'normal', 'hatespeech', 'normal', 'normal', 'offensive', 'normal', 'hatespeech', 'offensive', 'hatespeech', 'normal', 'normal', 'hatespeech', 'normal', 'normal', 'offensive', 'hatespeech', 'hatespeech', 'offensive', 'normal', 'normal', 'normal', 'hatespeech', 'hatespeech', 'normal', 'hatespeech', 'normal', 'normal', 'offensive', 'offensive', 'normal', 'offensive', 'hatespeech', 'hatespeech', 'offensive', 'normal', 'offensive', 'normal', 'hatespeech', 'normal', 'normal', 'offensive', 'hatespeech', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'hatespeech', 'hatespeech', 'hatespeech', 'normal', 'normal', 'hatespeech', 'hatespeech', 'hatespeech', 'hatespeech', 'normal', 'offensive', 'hatespeech', 'normal', 'hatespeech', 'hatespeech', 'offensive', 'hatespeech', 'normal', 'normal', 'hatespeech', 'hatespeech', 'normal', 'hatespeech', 'normal', 'hatespeech', 'offensive', 'offensive', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'hatespeech', 'normal', 'normal', 'normal', 'hatespeech', 'hatespeech', 'offensive', 'normal', 'offensive', 'offensive', 'normal', 'hatespeech', 'hatespeech', 'offensive', 'normal', 'normal', 'hatespeech', 'hatespeech', 'normal', 'normal', 'normal', 'offensive', 'normal', 'normal', 'offensive', 'hatespeech', 'hatespeech', 'hatespeech', 'normal', 'normal', 'normal', 'offensive', 'hatespeech', 'hatespeech', 'hatespeech', 'hatespeech', 'hatespeech', 'normal', 'normal', 'hatespeech', 'normal', 'normal', 'normal', 'normal', 'hatespeech', 'hatespeech', 'hatespeech', 'hatespeech', 'normal', 'normal', 'offensive', 'normal', 'hatespeech', 'hatespeech', 'normal', 'hatespeech', 'offensive', 'normal', 'normal', 'hatespeech', 'hatespeech', 'offensive', 'hatespeech', 'normal', 'normal', 'hatespeech', 'hatespeech', 'normal', 'offensive', 'normal', 'normal', 'normal', 'hatespeech', 'normal', 'normal', 'normal', 'hatespeech', 'hatespeech', 'normal', 'normal', 'hatespeech', 'normal', 'normal', 'normal', 'normal', 'hatespeech', 'normal', 'hatespeech', 'normal', 'normal', 'offensive', 'normal', 'normal', 'hatespeech', 'normal', 'hatespeech', 'hatespeech', 'hatespeech', 'normal', 'normal', 'hatespeech', 'hatespeech', 'hatespeech', 'hatespeech', 'normal', 'hatespeech', 'hatespeech', 'normal', 'normal', 'hatespeech', 'normal', 'hatespeech', 'normal', 'normal', 'hatespeech', 'hatespeech', 'hatespeech', 'normal', 'normal', 'hatespeech', 'normal', 'normal', 'offensive', 'normal', 'normal', 'offensive', 'normal', 'hatespeech', 'hatespeech', 'offensive', 'normal', 'normal', 'offensive', 'offensive', 'hatespeech', 'normal', 'normal', 'hatespeech', 'normal', 'hatespeech', 'normal', 'offensive', 'normal', 'offensive', 'normal', 'normal', 'hatespeech', 'hatespeech', 'normal', 'normal', 'normal', 'hatespeech', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'offensive', 'normal', 'offensive', 'normal', 'normal', 'hatespeech', 'offensive', 'offensive', 'offensive', 'offensive', 'normal', 'normal', 'hatespeech', 'normal', 'hatespeech', 'normal', 'normal', 'offensive', 'normal', 'hatespeech', 'normal', 'normal', 'hatespeech', 'hatespeech', 'hatespeech', 'hatespeech', 'offensive', 'hatespeech', 'normal', 'normal', 'normal', 'hatespeech', 'offensive', 'offensive', 'offensive', 'hatespeech', 'hatespeech', 'normal', 'hatespeech', 'normal', 'offensive', 'normal', 'hatespeech', 'normal', 'offensive', 'hatespeech', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'hatespeech', 'normal', 'hatespeech', 'normal', 'offensive', 'offensive', 'offensive', 'hatespeech', 'hatespeech', 'normal', 'normal', 'hatespeech', 'normal', 'normal', 'normal', 'normal', 'hatespeech', 'normal', 'normal', 'offensive', 'hatespeech', 'normal', 'normal', 'normal', 'hatespeech', 'normal', 'normal', 'normal', 'hatespeech', 'hatespeech', 'normal', 'normal', 'hatespeech', 'normal', 'normal', 'hatespeech', 'hatespeech', 'hatespeech', 'normal', 'hatespeech', 'normal', 'hatespeech', 'hatespeech', 'normal', 'hatespeech', 'normal', 'hatespeech', 'normal', 'normal', 'hatespeech', 'hatespeech', 'normal', 'normal', 'normal', 'offensive', 'offensive', 'normal', 'offensive', 'normal', 'hatespeech', 'offensive', 'normal', 'normal', 'hatespeech', 'normal', 'hatespeech', 'normal', 'normal', 'hatespeech', 'normal', 'offensive', 'normal', 'hatespeech', 'normal', 'hatespeech', 'hatespeech', 'normal', 'normal', 'hatespeech', 'offensive', 'hatespeech', 'hatespeech', 'normal', 'hatespeech', 'offensive', 'normal', 'hatespeech', 'normal', 'offensive', 'normal', 'normal', 'normal', 'hatespeech', 'normal', 'normal', 'offensive', 'normal', 'normal', 'offensive', 'hatespeech', 'hatespeech', 'hatespeech', 'hatespeech', 'normal', 'hatespeech', 'hatespeech', 'hatespeech', 'hatespeech', 'normal', 'hatespeech', 'normal', 'hatespeech', 'offensive', 'normal', 'hatespeech', 'offensive', 'normal', 'normal', 'normal', 'normal', 'offensive', 'normal', 'normal', 'hatespeech', 'normal', 'offensive', 'normal', 'hatespeech', 'normal', 'normal', 'hatespeech', 'normal', 'normal', 'hatespeech', 'normal', 'hatespeech', 'hatespeech', 'normal', 'hatespeech', 'normal', 'normal', 'normal', 'offensive', 'normal', 'normal', 'hatespeech', 'offensive', 'hatespeech', 'offensive', 'normal', 'offensive', 'offensive', 'normal', 'hatespeech', 'hatespeech', 'offensive', 'hatespeech', 'offensive', 'offensive', 'normal', 'normal', 'offensive', 'offensive', 'offensive', 'offensive', 'normal', 'offensive', 'hatespeech', 'offensive', 'offensive', 'offensive', 'hatespeech', 'offensive', 'offensive', 'offensive', 'offensive', 'normal', 'normal', 'offensive', 'offensive', 'offensive', 'offensive', 'offensive', 'normal', 'normal', 'offensive', 'normal', 'hatespeech', 'normal', 'offensive', 'offensive', 'normal', 'hatespeech', 'offensive', 'normal', 'offensive', 'normal', 'hatespeech', 'normal', 'hatespeech', 'offensive', 'normal', 'offensive', 'offensive', 'offensive', 'offensive', 'offensive', 'offensive', 'offensive', 'hatespeech', 'offensive', 'normal', 'offensive', 'offensive', 'normal', 'normal', 'offensive', 'offensive', 'normal', 'hatespeech', 'offensive', 'normal', 'offensive', 'normal', 'hatespeech', 'hatespeech', 'normal', 'hatespeech', 'offensive', 'offensive', 'normal', 'normal', 'hatespeech', 'offensive', 'normal', 'offensive', 'offensive', 'offensive', 'offensive', 'offensive', 'offensive', 'offensive', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'offensive', 'normal', 'normal', 'normal', 'normal', 'offensive', 'hatespeech', 'offensive', 'normal', 'hatespeech', 'offensive', 'hatespeech', 'offensive', 'normal', 'offensive', 'hatespeech', 'normal', 'offensive', 'offensive', 'normal', 'normal', 'offensive', 'offensive', 'offensive', 'offensive', 'normal', 'normal', 'normal', 'offensive', 'offensive', 'offensive', 'hatespeech', 'offensive', 'offensive', 'normal', 'normal', 'offensive', 'hatespeech', 'normal', 'normal', 'offensive', 'offensive', 'offensive', 'offensive', 'offensive', 'normal', 'normal', 'offensive', 'normal', 'offensive', 'normal', 'offensive', 'normal', 'offensive', 'hatespeech', 'normal', 'offensive', 'offensive', 'normal', 'offensive', 'normal', 'normal', 'normal', 'offensive', 'offensive', 'normal', 'offensive', 'normal', 'normal', 'offensive', 'normal', 'normal', 'offensive', 'offensive', 'normal', 'offensive', 'offensive', 'offensive', 'offensive', 'normal', 'normal', 'normal', 'offensive', 'normal', 'normal', 'normal', 'normal', 'offensive', 'offensive', 'offensive', 'offensive', 'hatespeech', 'normal', 'normal', 'offensive', 'offensive', 'offensive', 'normal', 'normal', 'normal', 'normal', 'normal', 'offensive', 'offensive', 'normal', 'normal', 'normal', 'hatespeech', 'offensive', 'normal', 'normal', 'normal', 'normal', 'normal', 'offensive', 'offensive', 'normal', 'offensive', 'normal', 'normal', 'offensive', 'normal', 'normal', 'offensive', 'offensive', 'normal', 'offensive', 'offensive', 'normal', 'hatespeech', 'offensive', 'normal', 'offensive', 'offensive', 'offensive', 'offensive', 'offensive', 'normal', 'offensive', 'offensive', 'offensive', 'normal', 'normal', 'offensive', 'normal', 'offensive', 'hatespeech', 'normal', 'normal', 'hatespeech', 'offensive', 'offensive', 'normal', 'hatespeech', 'offensive', 'normal', 'offensive', 'offensive', 'normal', 'normal', 'offensive', 'normal', 'offensive', 'offensive', 'offensive', 'offensive', 'hatespeech', 'offensive', 'offensive', 'offensive', 'normal', 'hatespeech', 'normal', 'normal', 'normal', 'hatespeech', 'offensive', 'normal', 'offensive', 'normal', 'offensive', 'normal', 'normal', 'offensive', 'offensive', 'offensive', 'normal', 'normal', 'normal', 'offensive', 'offensive', 'normal', 'offensive', 'normal', 'normal', 'offensive', 'offensive', 'offensive', 'offensive', 'normal', 'hatespeech', 'normal', 'normal', 'offensive', 'normal', 'normal', 'normal', 'hatespeech', 'offensive', 'offensive', 'offensive', 'normal', 'normal', 'offensive', 'normal', 'offensive', 'offensive', 'offensive', 'normal', 'offensive', 'offensive', 'offensive', 'normal', 'offensive', 'offensive', 'offensive', 'normal', 'offensive', 'normal', 'offensive', 'hatespeech', 'normal', 'offensive', 'normal', 'offensive', 'offensive', 'offensive', 'offensive', 'offensive', 'normal', 'hatespeech', 'normal', 'offensive', 'normal', 'hatespeech', 'hatespeech', 'normal', 'offensive', 'offensive', 'offensive', 'normal', 'normal', 'offensive', 'offensive', 'normal', 'normal', 'normal', 'hatespeech', 'normal', 'hatespeech', 'normal', 'hatespeech', 'offensive', 'offensive', 'normal', 'offensive', 'normal', 'offensive', 'normal', 'offensive', 'hatespeech', 'hatespeech', 'offensive', 'normal', 'hatespeech', 'normal', 'normal', 'hatespeech', 'offensive', 'offensive', 'offensive', 'normal', 'normal', 'offensive', 'hatespeech', 'offensive', 'hatespeech', 'hatespeech', 'normal', 'offensive', 'hatespeech', 'hatespeech', 'normal', 'hatespeech', 'offensive', 'hatespeech', 'normal', 'normal', 'normal', 'normal', 'offensive', 'offensive', 'offensive', 'offensive', 'offensive', 'hatespeech', 'offensive', 'offensive', 'normal', 'offensive', 'offensive', 'normal', 'offensive', 'hatespeech', 'offensive', 'offensive', 'offensive', 'offensive', 'normal', 'hatespeech', 'offensive', 'offensive', 'normal', 'hatespeech', 'normal', 'offensive', 'offensive', 'normal', 'hatespeech', 'hatespeech', 'offensive', 'offensive', 'offensive', 'hatespeech', 'normal', 'offensive', 'offensive', 'normal', 'offensive', 'offensive', 'hatespeech', 'offensive', 'offensive', 'normal', 'normal', 'normal', 'normal', 'offensive', 'normal', 'hatespeech', 'normal', 'offensive', 'offensive', 'normal', 'hatespeech', 'offensive', 'offensive', 'normal', 'normal', 'offensive', 'offensive', 'offensive', 'offensive', 'hatespeech', 'normal', 'normal', 'normal', 'normal', 'offensive', 'hatespeech', 'offensive', 'hatespeech', 'hatespeech', 'hatespeech', 'offensive', 'offensive', 'hatespeech', 'hatespeech', 'normal', 'offensive', 'hatespeech', 'hatespeech', 'normal', 'normal', 'offensive', 'offensive', 'hatespeech', 'offensive', 'offensive', 'offensive', 'offensive', 'offensive', 'hatespeech', 'normal', 'hatespeech', 'offensive', 'hatespeech', 'normal', 'offensive', 'offensive', 'normal', 'normal', 'normal', 'offensive', 'hatespeech', 'offensive', 'offensive', 'offensive', 'normal', 'hatespeech', 'hatespeech', 'normal', 'normal', 'offensive', 'hatespeech', 'hatespeech', 'normal', 'hatespeech', 'hatespeech', 'hatespeech', 'hatespeech', 'hatespeech', 'offensive', 'normal', 'normal', 'offensive', 'hatespeech', 'hatespeech', 'normal', 'normal', 'offensive', 'hatespeech', 'offensive', 'hatespeech', 'normal', 'normal', 'hatespeech', 'offensive', 'normal', 'offensive', 'hatespeech', 'hatespeech', 'offensive', 'offensive', 'hatespeech', 'hatespeech', 'offensive', 'offensive', 'normal', 'normal', 'normal', 'offensive', 'hatespeech', 'offensive', 'offensive', 'offensive', 'offensive', 'hatespeech', 'offensive', 'hatespeech', 'normal', 'hatespeech', 'offensive', 'normal', 'normal', 'offensive', 'hatespeech', 'normal', 'normal', 'offensive', 'offensive', 'normal', 'hatespeech', 'offensive', 'offensive', 'normal', 'offensive', 'offensive', 'offensive', 'normal', 'hatespeech', 'hatespeech', 'hatespeech', 'offensive', 'offensive', 'offensive', 'hatespeech', 'offensive', 'offensive', 'hatespeech', 'offensive', 'normal', 'hatespeech', 'offensive', 'normal', 'offensive', 'hatespeech', 'hatespeech', 'offensive', 'offensive', 'normal', 'hatespeech', 'hatespeech', 'offensive', 'hatespeech', 'hatespeech', 'hatespeech', 'offensive', 'hatespeech', 'hatespeech', 'offensive', 'hatespeech', 'normal', 'offensive', 'offensive', 'hatespeech', 'hatespeech', 'hatespeech', 'hatespeech', 'hatespeech', 'hatespeech', 'hatespeech', 'offensive', 'normal', 'offensive', 'offensive', 'offensive', 'hatespeech', 'hatespeech', 'offensive', 'hatespeech', 'normal', 'offensive', 'offensive', 'hatespeech', 'normal', 'normal', 'hatespeech', 'offensive', 'normal', 'normal', 'hatespeech', 'normal', 'offensive', 'offensive', 'normal', 'offensive', 'offensive', 'hatespeech', 'hatespeech', 'normal', 'hatespeech', 'normal', 'offensive', 'normal', 'offensive', 'offensive', 'offensive', 'offensive', 'normal', 'offensive', 'normal', 'hatespeech', 'hatespeech', 'hatespeech', 'hatespeech', 'offensive', 'normal', 'offensive', 'offensive', 'hatespeech', 'normal', 'hatespeech', 'offensive', 'offensive', 'offensive', 'offensive', 'normal', 'offensive', 'hatespeech', 'offensive', 'offensive', 'hatespeech', 'offensive', 'normal', 'hatespeech', 'normal', 'hatespeech', 'hatespeech', 'hatespeech', 'offensive', 'hatespeech', 'offensive', 'hatespeech', 'offensive', 'normal', 'normal', 'hatespeech', 'offensive', 'hatespeech', 'offensive', 'normal', 'offensive', 'offensive', 'normal', 'offensive', 'hatespeech', 'hatespeech', 'hatespeech', 'normal', 'hatespeech', 'hatespeech', 'normal', 'offensive', 'hatespeech', 'hatespeech', 'hatespeech', 'hatespeech', 'normal', 'normal', 'offensive', 'normal', 'offensive', 'normal', 'hatespeech', 'hatespeech', 'offensive', 'hatespeech', 'offensive', 'normal', 'offensive', 'hatespeech', 'hatespeech', 'hatespeech', 'normal', 'normal', 'offensive', 'normal', 'offensive', 'hatespeech', 'normal', 'hatespeech', 'offensive', 'hatespeech', 'offensive', 'offensive', 'offensive', 'offensive', 'hatespeech', 'offensive', 'hatespeech', 'offensive', 'normal', 'offensive', 'offensive', 'normal', 'offensive', 'normal', 'hatespeech', 'offensive', 'offensive', 'hatespeech', 'hatespeech', 'hatespeech', 'hatespeech', 'offensive', 'offensive', 'normal', 'offensive', 'offensive', 'normal', 'offensive', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'offensive', 'hatespeech', 'offensive', 'hatespeech', 'hatespeech', 'offensive', 'offensive', 'hatespeech', 'offensive', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'hatespeech', 'normal', 'hatespeech', 'hatespeech', 'hatespeech', 'offensive', 'normal', 'normal', 'offensive', 'normal', 'offensive', 'offensive', 'offensive', 'offensive', 'hatespeech', 'normal', 'offensive', 'offensive', 'hatespeech', 'offensive', 'normal', 'offensive', 'hatespeech', 'hatespeech', 'normal', 'offensive', 'hatespeech', 'offensive', 'offensive', 'hatespeech', 'offensive', 'normal', 'hatespeech', 'hatespeech', 'hatespeech', 'offensive', 'normal', 'hatespeech', 'hatespeech', 'offensive', 'offensive', 'offensive', 'offensive', 'offensive', 'hatespeech', 'offensive', 'normal', 'offensive', 'hatespeech', 'normal', 'normal', 'hatespeech', 'offensive', 'hatespeech', 'offensive', 'offensive', 'normal', 'offensive', 'offensive', 'normal', 'hatespeech', 'normal', 'hatespeech', 'hatespeech', 'hatespeech', 'offensive', 'offensive', 'offensive', 'normal', 'offensive', 'offensive', 'offensive', 'offensive', 'offensive', 'offensive', 'offensive', 'offensive', 'hatespeech', 'normal', 'offensive', 'hatespeech', 'normal', 'hatespeech', 'normal', 'normal', 'offensive', 'offensive', 'offensive', 'normal', 'offensive', 'normal', 'hatespeech', 'normal', 'normal', 'offensive', 'hatespeech', 'normal', 'normal', 'hatespeech', 'offensive', 'normal', 'hatespeech', 'offensive', 'offensive', 'offensive', 'hatespeech', 'normal'] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
            "  FutureWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1.0796857 0.8201194 1.1703163]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:54: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n",
            "\r0it [00:00, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 5 ========\n",
            "Training...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "481it [02:45,  2.92it/s]\n",
            "2it [00:00, 14.10it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "avg_train_loss 295.6874583159068\n",
            "model previously passed\n",
            "Running eval on  train ...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "481it [00:32, 14.85it/s]\n",
            "2it [00:00, 14.10it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Accuracy: 0.62\n",
            " Fscore: 0.62\n",
            " Precision: 0.65\n",
            " Recall: 0.61\n",
            " Roc Auc: 0.80\n",
            " Test took: 0:00:33\n",
            "model previously passed\n",
            "Running eval on  val ...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "61it [00:04, 15.06it/s]\n",
            "2it [00:00, 15.13it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Accuracy: 0.60\n",
            " Fscore: 0.59\n",
            " Precision: 0.64\n",
            " Recall: 0.58\n",
            " Roc Auc: 0.78\n",
            " Test took: 0:00:04\n",
            "model previously passed\n",
            "Running eval on  test ...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "61it [00:04, 15.23it/s]\n",
            "0it [00:00, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Accuracy: 0.60\n",
            " Fscore: 0.59\n",
            " Precision: 0.63\n",
            " Recall: 0.58\n",
            " Roc Auc: 0.78\n",
            " Test took: 0:00:04\n",
            "0.5928381017318737 0\n",
            "Saving model\n",
            "Saved/birnnscrat_lstm_64_3_100.pth\n",
            "\n",
            "======== Epoch 2 / 5 ========\n",
            "Training...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "481it [02:54,  2.76it/s]\n",
            "2it [00:00, 14.38it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "avg_train_loss 295.51231660267916\n",
            "model previously passed\n",
            "Running eval on  train ...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "481it [00:32, 14.61it/s]\n",
            "2it [00:00, 14.40it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Accuracy: 0.69\n",
            " Fscore: 0.67\n",
            " Precision: 0.69\n",
            " Recall: 0.67\n",
            " Roc Auc: 0.84\n",
            " Test took: 0:00:33\n",
            "model previously passed\n",
            "Running eval on  val ...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "61it [00:04, 14.83it/s]\n",
            "2it [00:00, 14.67it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Accuracy: 0.64\n",
            " Fscore: 0.62\n",
            " Precision: 0.64\n",
            " Recall: 0.62\n",
            " Roc Auc: 0.80\n",
            " Test took: 0:00:04\n",
            "model previously passed\n",
            "Running eval on  test ...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "61it [00:04, 14.53it/s]\n",
            "0it [00:00, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Accuracy: 0.65\n",
            " Fscore: 0.62\n",
            " Precision: 0.64\n",
            " Recall: 0.62\n",
            " Roc Auc: 0.80\n",
            " Test took: 0:00:04\n",
            "0.6166377960748289 0.5928381017318737\n",
            "Saving model\n",
            "Saved/birnnscrat_lstm_64_3_100.pth\n",
            "\n",
            "======== Epoch 3 / 5 ========\n",
            "Training...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "481it [03:14,  2.47it/s]\n",
            "2it [00:00, 14.04it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "avg_train_loss 295.4182916906916\n",
            "model previously passed\n",
            "Running eval on  train ...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "481it [00:32, 14.64it/s]\n",
            "2it [00:00, 14.10it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Accuracy: 0.75\n",
            " Fscore: 0.74\n",
            " Precision: 0.74\n",
            " Recall: 0.74\n",
            " Roc Auc: 0.89\n",
            " Test took: 0:00:33\n",
            "model previously passed\n",
            "Running eval on  val ...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "61it [00:04, 14.95it/s]\n",
            "2it [00:00, 14.66it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Accuracy: 0.64\n",
            " Fscore: 0.64\n",
            " Precision: 0.64\n",
            " Recall: 0.64\n",
            " Roc Auc: 0.81\n",
            " Test took: 0:00:04\n",
            "model previously passed\n",
            "Running eval on  test ...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "61it [00:04, 14.74it/s]\n",
            "0it [00:00, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Accuracy: 0.65\n",
            " Fscore: 0.64\n",
            " Precision: 0.64\n",
            " Recall: 0.64\n",
            " Roc Auc: 0.82\n",
            " Test took: 0:00:04\n",
            "0.6365513941496782 0.6166377960748289\n",
            "Saving model\n",
            "Saved/birnnscrat_lstm_64_3_100.pth\n",
            "\n",
            "======== Epoch 4 / 5 ========\n",
            "Training...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "481it [03:24,  2.36it/s]\n",
            "2it [00:00, 14.66it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "avg_train_loss 295.3653224381984\n",
            "model previously passed\n",
            "Running eval on  train ...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "481it [00:32, 14.59it/s]\n",
            "2it [00:00, 13.40it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Accuracy: 0.76\n",
            " Fscore: 0.76\n",
            " Precision: 0.78\n",
            " Recall: 0.76\n",
            " Roc Auc: 0.92\n",
            " Test took: 0:00:33\n",
            "model previously passed\n",
            "Running eval on  val ...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "61it [00:04, 13.60it/s]\n",
            "2it [00:00, 13.93it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Accuracy: 0.63\n",
            " Fscore: 0.63\n",
            " Precision: 0.66\n",
            " Recall: 0.62\n",
            " Roc Auc: 0.81\n",
            " Test took: 0:00:05\n",
            "model previously passed\n",
            "Running eval on  test ...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "61it [00:04, 14.00it/s]\n",
            "0it [00:00, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Accuracy: 0.62\n",
            " Fscore: 0.62\n",
            " Precision: 0.65\n",
            " Recall: 0.61\n",
            " Roc Auc: 0.81\n",
            " Test took: 0:00:04\n",
            "\n",
            "======== Epoch 5 / 5 ========\n",
            "Training...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "481it [03:29,  2.29it/s]\n",
            "2it [00:00, 14.07it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "avg_train_loss 295.29857389644377\n",
            "model previously passed\n",
            "Running eval on  train ...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "481it [00:32, 14.62it/s]\n",
            "2it [00:00, 14.88it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Accuracy: 0.81\n",
            " Fscore: 0.81\n",
            " Precision: 0.81\n",
            " Recall: 0.81\n",
            " Roc Auc: 0.93\n",
            " Test took: 0:00:33\n",
            "model previously passed\n",
            "Running eval on  val ...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "61it [00:04, 14.83it/s]\n",
            "2it [00:00, 15.09it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Accuracy: 0.64\n",
            " Fscore: 0.63\n",
            " Precision: 0.63\n",
            " Recall: 0.63\n",
            " Roc Auc: 0.79\n",
            " Test took: 0:00:04\n",
            "model previously passed\n",
            "Running eval on  test ...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "61it [00:04, 14.89it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Accuracy: 0.63\n",
            " Fscore: 0.62\n",
            " Precision: 0.62\n",
            " Recall: 0.62\n",
            " Roc Auc: 0.79\n",
            " Test took: 0:00:04\n",
            "best_val_fscore 0.6365513941496782\n",
            "best_test_fscore 0.6394014618815519\n",
            "best_val_rocauc 0.8117476454123843\n",
            "best_test_rocauc 0.8203029594853541\n",
            "best_val_precision 0.6370146992257849\n",
            "best_test_precision 0.6387270124237755\n",
            "best_val_recall 0.6361208687390083\n",
            "best_test_recall 0.6401887284784715\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "params['num_classes']=3\n",
        "params['data_file']=dict_data_folder[str(params['num_classes'])]['data_file']\n",
        "params['class_names']=dict_data_folder[str(params['num_classes'])]['class_label']\n",
        "if(params['num_classes']==2 and (params['auto_weights']==False)):\n",
        "      params['weights']=[1.0,1.0]\n",
        "        \n",
        "#for att_lambda in [0.001,0.01,0.1,1,10,100]\n",
        "train_model(params,device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LRkvPokoMg3f",
        "outputId": "227896b0-60e2-4791-cac5-25bd5909895a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "127"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import gc\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "34jLhxdQ5stq",
        "outputId": "e7e12551-372e-4182-eeba-5f6a0a1c6ade"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ekphrasis/classes/tokenizer.py:225: FutureWarning: Possible nested set at position 2190\n",
            "  self.tok = re.compile(r\"({})\".format(\"|\".join(pipeline)))\n",
            "Reading twitter - 1grams ...\n",
            "Reading twitter - 2grams ...\n",
            "/usr/local/lib/python3.7/dist-packages/ekphrasis/classes/exmanager.py:14: FutureWarning: Possible nested set at position 42\n",
            "  regexes = {k.lower(): re.compile(self.expressions[k]) for k, v in\n",
            "Reading english - 1grams ...\n",
            "Since you dont want to use GPU, using the CPU instead.\n",
            "tcmalloc: large alloc 2300993536 bytes == 0x3ebec000 @  0x7f3ec03471e7 0x4b2150 0x5ac2ec 0x5e3d6d 0x58ee7f 0x590c9f 0x591039 0x4fb96a 0x4fc108 0x4fe054 0x5ef9b8 0x58eb9c 0x51b4e6 0x58f2a7 0x51740e 0x5b4a3e 0x58f49e 0x51837f 0x5b41c5 0x58f49e 0x51837f 0x5b41c5 0x604133 0x606e06 0x606ecc 0x609aa6 0x64d332 0x64d4de 0x7f3ebff44c87 0x5b561a\n",
            "tcmalloc: large alloc 2300993536 bytes == 0xc7e52000 @  0x7f3ec03471e7 0x4b2150 0x5ac2ec 0x4fc11a 0x4fe054 0x5ef9b8 0x58eb9c 0x51b4e6 0x58f2a7 0x51740e 0x5b4a3e 0x58f49e 0x51837f 0x5b41c5 0x58f49e 0x51837f 0x5b41c5 0x604133 0x606e06 0x606ecc 0x609aa6 0x64d332 0x64d4de 0x7f3ebff44c87 0x5b561a\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:70: FutureWarning: Pass classes=['hatespeech' 'normal' 'offensive'], y=['normal', 'hatespeech', 'normal', 'normal', 'offensive', 'normal', 'normal', 'hatespeech', 'normal', 'offensive', 'hatespeech', 'normal', 'normal', 'offensive', 'hatespeech', 'normal', 'normal', 'normal', 'normal', 'offensive', 'offensive', 'offensive', 'normal', 'offensive', 'hatespeech', 'hatespeech', 'hatespeech', 'normal', 'hatespeech', 'hatespeech', 'normal', 'offensive', 'normal', 'hatespeech', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'hatespeech', 'normal', 'normal', 'hatespeech', 'normal', 'normal', 'hatespeech', 'offensive', 'offensive', 'hatespeech', 'normal', 'hatespeech', 'hatespeech', 'normal', 'offensive', 'hatespeech', 'hatespeech', 'normal', 'offensive', 'offensive', 'hatespeech', 'normal', 'hatespeech', 'normal', 'normal', 'hatespeech', 'normal', 'hatespeech', 'hatespeech', 'offensive', 'hatespeech', 'normal', 'normal', 'hatespeech', 'normal', 'hatespeech', 'normal', 'hatespeech', 'hatespeech', 'offensive', 'normal', 'normal', 'hatespeech', 'hatespeech', 'offensive', 'normal', 'hatespeech', 'normal', 'hatespeech', 'hatespeech', 'normal', 'normal', 'normal', 'normal', 'hatespeech', 'normal', 'normal', 'normal', 'normal', 'hatespeech', 'hatespeech', 'hatespeech', 'hatespeech', 'normal', 'hatespeech', 'normal', 'hatespeech', 'normal', 'hatespeech', 'hatespeech', 'hatespeech', 'hatespeech', 'hatespeech', 'normal', 'normal', 'normal', 'offensive', 'hatespeech', 'normal', 'normal', 'normal', 'hatespeech', 'hatespeech', 'normal', 'normal', 'normal', 'normal', 'normal', 'hatespeech', 'hatespeech', 'hatespeech', 'hatespeech', 'normal', 'normal', 'normal', 'offensive', 'offensive', 'normal', 'hatespeech', 'hatespeech', 'hatespeech', 'normal', 'normal', 'offensive', 'hatespeech', 'normal', 'hatespeech', 'offensive', 'hatespeech', 'normal', 'normal', 'hatespeech', 'normal', 'hatespeech', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'hatespeech', 'normal', 'hatespeech', 'hatespeech', 'normal', 'hatespeech', 'offensive', 'normal', 'hatespeech', 'offensive', 'hatespeech', 'offensive', 'normal', 'normal', 'normal', 'hatespeech', 'hatespeech', 'hatespeech', 'hatespeech', 'hatespeech', 'hatespeech', 'hatespeech', 'hatespeech', 'normal', 'hatespeech', 'normal', 'hatespeech', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'hatespeech', 'hatespeech', 'offensive', 'offensive', 'normal', 'offensive', 'hatespeech', 'normal', 'normal', 'hatespeech', 'hatespeech', 'normal', 'hatespeech', 'normal', 'offensive', 'normal', 'offensive', 'normal', 'normal', 'hatespeech', 'hatespeech', 'hatespeech', 'hatespeech', 'normal', 'normal', 'normal', 'normal', 'offensive', 'hatespeech', 'normal', 'hatespeech', 'normal', 'offensive', 'normal', 'normal', 'normal', 'normal', 'hatespeech', 'hatespeech', 'hatespeech', 'normal', 'normal', 'normal', 'normal', 'offensive', 'offensive', 'normal', 'normal', 'hatespeech', 'hatespeech', 'normal', 'hatespeech', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'offensive', 'hatespeech', 'normal', 'hatespeech', 'normal', 'hatespeech', 'normal', 'hatespeech', 'offensive', 'normal', 'hatespeech', 'hatespeech', 'normal', 'offensive', 'normal', 'hatespeech', 'hatespeech', 'normal', 'hatespeech', 'normal', 'normal', 'normal', 'hatespeech', 'hatespeech', 'hatespeech', 'normal', 'hatespeech', 'normal', 'hatespeech', 'hatespeech', 'normal', 'offensive', 'hatespeech', 'normal', 'normal', 'hatespeech', 'hatespeech', 'hatespeech', 'hatespeech', 'hatespeech', 'hatespeech', 'hatespeech', 'normal', 'hatespeech', 'normal', 'normal', 'normal', 'offensive', 'normal', 'offensive', 'normal', 'normal', 'normal', 'normal', 'hatespeech', 'hatespeech', 'hatespeech', 'hatespeech', 'hatespeech', 'hatespeech', 'normal', 'hatespeech', 'hatespeech', 'hatespeech', 'hatespeech', 'hatespeech', 'normal', 'offensive', 'normal', 'hatespeech', 'hatespeech', 'normal', 'hatespeech', 'hatespeech', 'hatespeech', 'hatespeech', 'hatespeech', 'normal', 'hatespeech', 'hatespeech', 'normal', 'offensive', 'normal', 'normal', 'offensive', 'hatespeech', 'normal', 'normal', 'offensive', 'offensive', 'hatespeech', 'offensive', 'normal', 'offensive', 'hatespeech', 'normal', 'offensive', 'normal', 'hatespeech', 'normal', 'normal', 'normal', 'hatespeech', 'hatespeech', 'offensive', 'normal', 'hatespeech', 'normal', 'normal', 'normal', 'hatespeech', 'hatespeech', 'hatespeech', 'hatespeech', 'hatespeech', 'normal', 'offensive', 'hatespeech', 'normal', 'hatespeech', 'offensive', 'normal', 'hatespeech', 'normal', 'normal', 'normal', 'offensive', 'hatespeech', 'hatespeech', 'normal', 'hatespeech', 'normal', 'normal', 'hatespeech', 'hatespeech', 'normal', 'offensive', 'hatespeech', 'hatespeech', 'normal', 'hatespeech', 'hatespeech', 'hatespeech', 'hatespeech', 'normal', 'offensive', 'normal', 'hatespeech', 'offensive', 'hatespeech', 'hatespeech', 'hatespeech', 'hatespeech', 'hatespeech', 'hatespeech', 'normal', 'hatespeech', 'hatespeech', 'hatespeech', 'hatespeech', 'hatespeech', 'normal', 'normal', 'offensive', 'hatespeech', 'normal', 'normal', 'hatespeech', 'hatespeech', 'hatespeech', 'hatespeech', 'normal', 'offensive', 'hatespeech', 'normal', 'normal', 'normal', 'offensive', 'hatespeech', 'hatespeech', 'normal', 'offensive', 'offensive', 'hatespeech', 'normal', 'normal', 'normal', 'normal', 'normal', 'offensive', 'hatespeech', 'hatespeech', 'offensive', 'hatespeech', 'offensive', 'normal', 'normal', 'hatespeech', 'offensive', 'hatespeech', 'normal', 'offensive', 'normal', 'hatespeech', 'normal', 'normal', 'normal', 'offensive', 'offensive', 'normal', 'hatespeech', 'hatespeech', 'hatespeech', 'normal', 'normal', 'hatespeech', 'hatespeech', 'hatespeech', 'hatespeech', 'hatespeech', 'hatespeech', 'hatespeech', 'normal', 'hatespeech', 'normal', 'normal', 'normal', 'normal', 'normal', 'offensive', 'offensive', 'offensive', 'normal', 'offensive', 'hatespeech', 'normal', 'hatespeech', 'offensive', 'normal', 'hatespeech', 'hatespeech', 'normal', 'hatespeech', 'hatespeech', 'hatespeech', 'offensive', 'normal', 'normal', 'hatespeech', 'normal', 'hatespeech', 'hatespeech', 'hatespeech', 'offensive', 'normal', 'normal', 'normal', 'offensive', 'normal', 'normal', 'hatespeech', 'normal', 'hatespeech', 'normal', 'normal', 'normal', 'hatespeech', 'hatespeech', 'normal', 'normal', 'hatespeech', 'normal', 'hatespeech', 'normal', 'normal', 'normal', 'offensive', 'hatespeech', 'hatespeech', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'hatespeech', 'offensive', 'hatespeech', 'hatespeech', 'hatespeech', 'normal', 'hatespeech', 'normal', 'hatespeech', 'normal', 'normal', 'offensive', 'hatespeech', 'normal', 'normal', 'hatespeech', 'normal', 'offensive', 'normal', 'normal', 'hatespeech', 'offensive', 'normal', 'normal', 'offensive', 'hatespeech', 'normal', 'offensive', 'hatespeech', 'normal', 'normal', 'normal', 'hatespeech', 'normal', 'normal', 'offensive', 'normal', 'hatespeech', 'offensive', 'hatespeech', 'normal', 'normal', 'hatespeech', 'normal', 'normal', 'offensive', 'hatespeech', 'hatespeech', 'offensive', 'normal', 'normal', 'normal', 'hatespeech', 'hatespeech', 'normal', 'hatespeech', 'normal', 'normal', 'offensive', 'offensive', 'normal', 'offensive', 'hatespeech', 'hatespeech', 'offensive', 'normal', 'offensive', 'normal', 'hatespeech', 'normal', 'normal', 'offensive', 'hatespeech', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'hatespeech', 'hatespeech', 'hatespeech', 'normal', 'normal', 'hatespeech', 'hatespeech', 'hatespeech', 'hatespeech', 'normal', 'offensive', 'hatespeech', 'normal', 'hatespeech', 'hatespeech', 'offensive', 'hatespeech', 'normal', 'normal', 'hatespeech', 'hatespeech', 'normal', 'hatespeech', 'normal', 'hatespeech', 'offensive', 'offensive', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'hatespeech', 'normal', 'normal', 'normal', 'hatespeech', 'hatespeech', 'offensive', 'normal', 'offensive', 'offensive', 'normal', 'hatespeech', 'hatespeech', 'offensive', 'normal', 'normal', 'hatespeech', 'hatespeech', 'normal', 'normal', 'normal', 'offensive', 'normal', 'normal', 'offensive', 'hatespeech', 'hatespeech', 'hatespeech', 'normal', 'normal', 'normal', 'offensive', 'hatespeech', 'hatespeech', 'hatespeech', 'hatespeech', 'hatespeech', 'normal', 'normal', 'hatespeech', 'normal', 'normal', 'normal', 'normal', 'hatespeech', 'hatespeech', 'hatespeech', 'hatespeech', 'normal', 'normal', 'offensive', 'normal', 'hatespeech', 'hatespeech', 'normal', 'hatespeech', 'offensive', 'normal', 'normal', 'hatespeech', 'hatespeech', 'offensive', 'hatespeech', 'normal', 'normal', 'hatespeech', 'hatespeech', 'normal', 'offensive', 'normal', 'normal', 'normal', 'hatespeech', 'normal', 'normal', 'normal', 'hatespeech', 'hatespeech', 'normal', 'normal', 'hatespeech', 'normal', 'normal', 'normal', 'normal', 'hatespeech', 'normal', 'hatespeech', 'normal', 'normal', 'offensive', 'normal', 'normal', 'hatespeech', 'normal', 'hatespeech', 'hatespeech', 'hatespeech', 'normal', 'normal', 'hatespeech', 'hatespeech', 'hatespeech', 'hatespeech', 'normal', 'hatespeech', 'hatespeech', 'normal', 'normal', 'hatespeech', 'normal', 'hatespeech', 'normal', 'normal', 'hatespeech', 'hatespeech', 'hatespeech', 'normal', 'normal', 'hatespeech', 'normal', 'normal', 'offensive', 'normal', 'normal', 'offensive', 'normal', 'hatespeech', 'hatespeech', 'offensive', 'normal', 'normal', 'offensive', 'offensive', 'hatespeech', 'normal', 'normal', 'hatespeech', 'normal', 'hatespeech', 'normal', 'offensive', 'normal', 'offensive', 'normal', 'normal', 'hatespeech', 'hatespeech', 'normal', 'normal', 'normal', 'hatespeech', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'offensive', 'normal', 'offensive', 'normal', 'normal', 'hatespeech', 'offensive', 'offensive', 'offensive', 'offensive', 'normal', 'normal', 'hatespeech', 'normal', 'hatespeech', 'normal', 'normal', 'offensive', 'normal', 'hatespeech', 'normal', 'normal', 'hatespeech', 'hatespeech', 'hatespeech', 'hatespeech', 'offensive', 'hatespeech', 'normal', 'normal', 'normal', 'hatespeech', 'offensive', 'offensive', 'offensive', 'hatespeech', 'hatespeech', 'normal', 'hatespeech', 'normal', 'offensive', 'normal', 'hatespeech', 'normal', 'offensive', 'hatespeech', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'hatespeech', 'normal', 'hatespeech', 'normal', 'offensive', 'offensive', 'offensive', 'hatespeech', 'hatespeech', 'normal', 'normal', 'hatespeech', 'normal', 'normal', 'normal', 'normal', 'hatespeech', 'normal', 'normal', 'offensive', 'hatespeech', 'normal', 'normal', 'normal', 'hatespeech', 'normal', 'normal', 'normal', 'hatespeech', 'hatespeech', 'normal', 'normal', 'hatespeech', 'normal', 'normal', 'hatespeech', 'hatespeech', 'hatespeech', 'normal', 'hatespeech', 'normal', 'hatespeech', 'hatespeech', 'normal', 'hatespeech', 'normal', 'hatespeech', 'normal', 'normal', 'hatespeech', 'hatespeech', 'normal', 'normal', 'normal', 'offensive', 'offensive', 'normal', 'offensive', 'normal', 'hatespeech', 'offensive', 'normal', 'normal', 'hatespeech', 'normal', 'hatespeech', 'normal', 'normal', 'hatespeech', 'normal', 'offensive', 'normal', 'hatespeech', 'normal', 'hatespeech', 'hatespeech', 'normal', 'normal', 'hatespeech', 'offensive', 'hatespeech', 'hatespeech', 'normal', 'hatespeech', 'offensive', 'normal', 'hatespeech', 'normal', 'offensive', 'normal', 'normal', 'normal', 'hatespeech', 'normal', 'normal', 'offensive', 'normal', 'normal', 'offensive', 'hatespeech', 'hatespeech', 'hatespeech', 'hatespeech', 'normal', 'hatespeech', 'hatespeech', 'hatespeech', 'hatespeech', 'normal', 'hatespeech', 'normal', 'hatespeech', 'offensive', 'normal', 'hatespeech', 'offensive', 'normal', 'normal', 'normal', 'normal', 'offensive', 'normal', 'normal', 'hatespeech', 'normal', 'offensive', 'normal', 'hatespeech', 'normal', 'normal', 'hatespeech', 'normal', 'normal', 'hatespeech', 'normal', 'hatespeech', 'hatespeech', 'normal', 'hatespeech', 'normal', 'normal', 'normal', 'offensive', 'normal', 'normal', 'hatespeech', 'offensive', 'hatespeech', 'offensive', 'normal', 'offensive', 'offensive', 'normal', 'hatespeech', 'hatespeech', 'offensive', 'hatespeech', 'offensive', 'offensive', 'normal', 'normal', 'offensive', 'offensive', 'offensive', 'offensive', 'normal', 'offensive', 'hatespeech', 'offensive', 'offensive', 'offensive', 'hatespeech', 'offensive', 'offensive', 'offensive', 'offensive', 'normal', 'normal', 'offensive', 'offensive', 'offensive', 'offensive', 'offensive', 'normal', 'normal', 'offensive', 'normal', 'hatespeech', 'normal', 'offensive', 'offensive', 'normal', 'hatespeech', 'offensive', 'normal', 'offensive', 'normal', 'hatespeech', 'normal', 'hatespeech', 'offensive', 'normal', 'offensive', 'offensive', 'offensive', 'offensive', 'offensive', 'offensive', 'offensive', 'hatespeech', 'offensive', 'normal', 'offensive', 'offensive', 'normal', 'normal', 'offensive', 'offensive', 'normal', 'hatespeech', 'offensive', 'normal', 'offensive', 'normal', 'hatespeech', 'hatespeech', 'normal', 'hatespeech', 'offensive', 'offensive', 'normal', 'normal', 'hatespeech', 'offensive', 'normal', 'offensive', 'offensive', 'offensive', 'offensive', 'offensive', 'offensive', 'offensive', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'offensive', 'normal', 'normal', 'normal', 'normal', 'offensive', 'hatespeech', 'offensive', 'normal', 'hatespeech', 'offensive', 'hatespeech', 'offensive', 'normal', 'offensive', 'hatespeech', 'normal', 'offensive', 'offensive', 'normal', 'normal', 'offensive', 'offensive', 'offensive', 'offensive', 'normal', 'normal', 'normal', 'offensive', 'offensive', 'offensive', 'hatespeech', 'offensive', 'offensive', 'normal', 'normal', 'offensive', 'hatespeech', 'normal', 'normal', 'offensive', 'offensive', 'offensive', 'offensive', 'offensive', 'normal', 'normal', 'offensive', 'normal', 'offensive', 'normal', 'offensive', 'normal', 'offensive', 'hatespeech', 'normal', 'offensive', 'offensive', 'normal', 'offensive', 'normal', 'normal', 'normal', 'offensive', 'offensive', 'normal', 'offensive', 'normal', 'normal', 'offensive', 'normal', 'normal', 'offensive', 'offensive', 'normal', 'offensive', 'offensive', 'offensive', 'offensive', 'normal', 'normal', 'normal', 'offensive', 'normal', 'normal', 'normal', 'normal', 'offensive', 'offensive', 'offensive', 'offensive', 'hatespeech', 'normal', 'normal', 'offensive', 'offensive', 'offensive', 'normal', 'normal', 'normal', 'normal', 'normal', 'offensive', 'offensive', 'normal', 'normal', 'normal', 'hatespeech', 'offensive', 'normal', 'normal', 'normal', 'normal', 'normal', 'offensive', 'offensive', 'normal', 'offensive', 'normal', 'normal', 'offensive', 'normal', 'normal', 'offensive', 'offensive', 'normal', 'offensive', 'offensive', 'normal', 'hatespeech', 'offensive', 'normal', 'offensive', 'offensive', 'offensive', 'offensive', 'offensive', 'normal', 'offensive', 'offensive', 'offensive', 'normal', 'normal', 'offensive', 'normal', 'offensive', 'hatespeech', 'normal', 'normal', 'hatespeech', 'offensive', 'offensive', 'normal', 'hatespeech', 'offensive', 'normal', 'offensive', 'offensive', 'normal', 'normal', 'offensive', 'normal', 'offensive', 'offensive', 'offensive', 'offensive', 'hatespeech', 'offensive', 'offensive', 'offensive', 'normal', 'hatespeech', 'normal', 'normal', 'normal', 'hatespeech', 'offensive', 'normal', 'offensive', 'normal', 'offensive', 'normal', 'normal', 'offensive', 'offensive', 'offensive', 'normal', 'normal', 'normal', 'offensive', 'offensive', 'normal', 'offensive', 'normal', 'normal', 'offensive', 'offensive', 'offensive', 'offensive', 'normal', 'hatespeech', 'normal', 'normal', 'offensive', 'normal', 'normal', 'normal', 'hatespeech', 'offensive', 'offensive', 'offensive', 'normal', 'normal', 'offensive', 'normal', 'offensive', 'offensive', 'offensive', 'normal', 'offensive', 'offensive', 'offensive', 'normal', 'offensive', 'offensive', 'offensive', 'normal', 'offensive', 'normal', 'offensive', 'hatespeech', 'normal', 'offensive', 'normal', 'offensive', 'offensive', 'offensive', 'offensive', 'offensive', 'normal', 'hatespeech', 'normal', 'offensive', 'normal', 'hatespeech', 'hatespeech', 'normal', 'offensive', 'offensive', 'offensive', 'normal', 'normal', 'offensive', 'offensive', 'normal', 'normal', 'normal', 'hatespeech', 'normal', 'hatespeech', 'normal', 'hatespeech', 'offensive', 'offensive', 'normal', 'offensive', 'normal', 'offensive', 'normal', 'offensive', 'hatespeech', 'hatespeech', 'offensive', 'normal', 'hatespeech', 'normal', 'normal', 'hatespeech', 'offensive', 'offensive', 'offensive', 'normal', 'normal', 'offensive', 'hatespeech', 'offensive', 'hatespeech', 'hatespeech', 'normal', 'offensive', 'hatespeech', 'hatespeech', 'normal', 'hatespeech', 'offensive', 'hatespeech', 'normal', 'normal', 'normal', 'normal', 'offensive', 'offensive', 'offensive', 'offensive', 'offensive', 'hatespeech', 'offensive', 'offensive', 'normal', 'offensive', 'offensive', 'normal', 'offensive', 'hatespeech', 'offensive', 'offensive', 'offensive', 'offensive', 'normal', 'hatespeech', 'offensive', 'offensive', 'normal', 'hatespeech', 'normal', 'offensive', 'offensive', 'normal', 'hatespeech', 'hatespeech', 'offensive', 'offensive', 'offensive', 'hatespeech', 'normal', 'offensive', 'offensive', 'normal', 'offensive', 'offensive', 'hatespeech', 'offensive', 'offensive', 'normal', 'normal', 'normal', 'normal', 'offensive', 'normal', 'hatespeech', 'normal', 'offensive', 'offensive', 'normal', 'hatespeech', 'offensive', 'offensive', 'normal', 'normal', 'offensive', 'offensive', 'offensive', 'offensive', 'hatespeech', 'normal', 'normal', 'normal', 'normal', 'offensive', 'hatespeech', 'offensive', 'hatespeech', 'hatespeech', 'hatespeech', 'offensive', 'offensive', 'hatespeech', 'hatespeech', 'normal', 'offensive', 'hatespeech', 'hatespeech', 'normal', 'normal', 'offensive', 'offensive', 'hatespeech', 'offensive', 'offensive', 'offensive', 'offensive', 'offensive', 'hatespeech', 'normal', 'hatespeech', 'offensive', 'hatespeech', 'normal', 'offensive', 'offensive', 'normal', 'normal', 'normal', 'offensive', 'hatespeech', 'offensive', 'offensive', 'offensive', 'normal', 'hatespeech', 'hatespeech', 'normal', 'normal', 'offensive', 'hatespeech', 'hatespeech', 'normal', 'hatespeech', 'hatespeech', 'hatespeech', 'hatespeech', 'hatespeech', 'offensive', 'normal', 'normal', 'offensive', 'hatespeech', 'hatespeech', 'normal', 'normal', 'offensive', 'hatespeech', 'offensive', 'hatespeech', 'normal', 'normal', 'hatespeech', 'offensive', 'normal', 'offensive', 'hatespeech', 'hatespeech', 'offensive', 'offensive', 'hatespeech', 'hatespeech', 'offensive', 'offensive', 'normal', 'normal', 'normal', 'offensive', 'hatespeech', 'offensive', 'offensive', 'offensive', 'offensive', 'hatespeech', 'offensive', 'hatespeech', 'normal', 'hatespeech', 'offensive', 'normal', 'normal', 'offensive', 'hatespeech', 'normal', 'normal', 'offensive', 'offensive', 'normal', 'hatespeech', 'offensive', 'offensive', 'normal', 'offensive', 'offensive', 'offensive', 'normal', 'hatespeech', 'hatespeech', 'hatespeech', 'offensive', 'offensive', 'offensive', 'hatespeech', 'offensive', 'offensive', 'hatespeech', 'offensive', 'normal', 'hatespeech', 'offensive', 'normal', 'offensive', 'hatespeech', 'hatespeech', 'offensive', 'offensive', 'normal', 'hatespeech', 'hatespeech', 'offensive', 'hatespeech', 'hatespeech', 'hatespeech', 'offensive', 'hatespeech', 'hatespeech', 'offensive', 'hatespeech', 'normal', 'offensive', 'offensive', 'hatespeech', 'hatespeech', 'hatespeech', 'hatespeech', 'hatespeech', 'hatespeech', 'hatespeech', 'offensive', 'normal', 'offensive', 'offensive', 'offensive', 'hatespeech', 'hatespeech', 'offensive', 'hatespeech', 'normal', 'offensive', 'offensive', 'hatespeech', 'normal', 'normal', 'hatespeech', 'offensive', 'normal', 'normal', 'hatespeech', 'normal', 'offensive', 'offensive', 'normal', 'offensive', 'offensive', 'hatespeech', 'hatespeech', 'normal', 'hatespeech', 'normal', 'offensive', 'normal', 'offensive', 'offensive', 'offensive', 'offensive', 'normal', 'offensive', 'normal', 'hatespeech', 'hatespeech', 'hatespeech', 'hatespeech', 'offensive', 'normal', 'offensive', 'offensive', 'hatespeech', 'normal', 'hatespeech', 'offensive', 'offensive', 'offensive', 'offensive', 'normal', 'offensive', 'hatespeech', 'offensive', 'offensive', 'hatespeech', 'offensive', 'normal', 'hatespeech', 'normal', 'hatespeech', 'hatespeech', 'hatespeech', 'offensive', 'hatespeech', 'offensive', 'hatespeech', 'offensive', 'normal', 'normal', 'hatespeech', 'offensive', 'hatespeech', 'offensive', 'normal', 'offensive', 'offensive', 'normal', 'offensive', 'hatespeech', 'hatespeech', 'hatespeech', 'normal', 'hatespeech', 'hatespeech', 'normal', 'offensive', 'hatespeech', 'hatespeech', 'hatespeech', 'hatespeech', 'normal', 'normal', 'offensive', 'normal', 'offensive', 'normal', 'hatespeech', 'hatespeech', 'offensive', 'hatespeech', 'offensive', 'normal', 'offensive', 'hatespeech', 'hatespeech', 'hatespeech', 'normal', 'normal', 'offensive', 'normal', 'offensive', 'hatespeech', 'normal', 'hatespeech', 'offensive', 'hatespeech', 'offensive', 'offensive', 'offensive', 'offensive', 'hatespeech', 'offensive', 'hatespeech', 'offensive', 'normal', 'offensive', 'offensive', 'normal', 'offensive', 'normal', 'hatespeech', 'offensive', 'offensive', 'hatespeech', 'hatespeech', 'hatespeech', 'hatespeech', 'offensive', 'offensive', 'normal', 'offensive', 'offensive', 'normal', 'offensive', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'offensive', 'hatespeech', 'offensive', 'hatespeech', 'hatespeech', 'offensive', 'offensive', 'hatespeech', 'offensive', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'hatespeech', 'normal', 'hatespeech', 'hatespeech', 'hatespeech', 'offensive', 'normal', 'normal', 'offensive', 'normal', 'offensive', 'offensive', 'offensive', 'offensive', 'hatespeech', 'normal', 'offensive', 'offensive', 'hatespeech', 'offensive', 'normal', 'offensive', 'hatespeech', 'hatespeech', 'normal', 'offensive', 'hatespeech', 'offensive', 'offensive', 'hatespeech', 'offensive', 'normal', 'hatespeech', 'hatespeech', 'hatespeech', 'offensive', 'normal', 'hatespeech', 'hatespeech', 'offensive', 'offensive', 'offensive', 'offensive', 'offensive', 'hatespeech', 'offensive', 'normal', 'offensive', 'hatespeech', 'normal', 'normal', 'hatespeech', 'offensive', 'hatespeech', 'offensive', 'offensive', 'normal', 'offensive', 'offensive', 'normal', 'hatespeech', 'normal', 'hatespeech', 'hatespeech', 'hatespeech', 'offensive', 'offensive', 'offensive', 'normal', 'offensive', 'offensive', 'offensive', 'offensive', 'offensive', 'offensive', 'offensive', 'offensive', 'hatespeech', 'normal', 'offensive', 'hatespeech', 'normal', 'hatespeech', 'normal', 'normal', 'offensive', 'offensive', 'offensive', 'normal', 'offensive', 'normal', 'hatespeech', 'normal', 'normal', 'offensive', 'hatespeech', 'normal', 'normal', 'hatespeech', 'offensive', 'normal', 'hatespeech', 'offensive', 'offensive', 'offensive', 'hatespeech', 'normal'] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
            "  FutureWarning)\n",
            "total_data 1142\n",
            "100% 1142/1142 [00:01<00:00, 633.20it/s]\n",
            "100% 1142/1142 [00:00<00:00, 8191.78it/s]\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:54: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n",
            "Saved/birnnscrat_lstm_64_3_100.pth\n",
            "Running eval on test data...\n",
            "100% 36/36 [00:02<00:00, 14.02it/s]\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            " Accuracy: 0.622\n",
            " Fscore: 0.457\n",
            " Precision: 0.520\n",
            " Recall: 0.411\n",
            " Test took: 0:00:03\n",
            "100% 1142/1142 [00:00<00:00, 3888.26it/s]\n",
            "Since you dont want to use GPU, using the CPU instead.\n",
            "tcmalloc: large alloc 2300993536 bytes == 0x43bee000 @  0x7f3ec03471e7 0x4b2150 0x5ac2ec 0x5e3d6d 0x58ee7f 0x590c9f 0x591039 0x4fb96a 0x4fc108 0x4fe054 0x5ef9b8 0x58eb9c 0x51b4e6 0x58f2a7 0x51740e 0x5b4a3e 0x58f49e 0x51837f 0x5b41c5 0x58f49e 0x51837f 0x5b41c5 0x604133 0x606e06 0x606ecc 0x609aa6 0x64d332 0x64d4de 0x7f3ebff44c87 0x5b561a\n",
            "tcmalloc: large alloc 2300993536 bytes == 0xcce54000 @  0x7f3ec03471e7 0x4b2150 0x5ac2ec 0x4fc11a 0x4fe054 0x5ef9b8 0x58eb9c 0x51b4e6 0x58f2a7 0x51740e 0x5b4a3e 0x58f49e 0x51837f 0x5b41c5 0x58f49e 0x51837f 0x5b41c5 0x604133 0x606e06 0x606ecc 0x609aa6 0x64d332 0x64d4de 0x7f3ebff44c87 0x5b561a\n",
            "100% 1142/1142 [00:00<00:00, 5967.18it/s]\n",
            "Saved/birnnscrat_lstm_64_3_100.pth\n",
            "Running eval on test data...\n",
            "100% 36/36 [00:02<00:00, 14.64it/s]\n",
            "100% 1142/1142 [00:00<00:00, 1633.30it/s]\n",
            "Since you dont want to use GPU, using the CPU instead.\n",
            "tcmalloc: large alloc 2300993536 bytes == 0x43bee000 @  0x7f3ec03471e7 0x4b2150 0x5ac2ec 0x5e3d6d 0x58ee7f 0x590c9f 0x591039 0x4fb96a 0x4fc108 0x4fe054 0x5ef9b8 0x58eb9c 0x51b4e6 0x58f2a7 0x51740e 0x5b4a3e 0x58f49e 0x51837f 0x5b41c5 0x58f49e 0x51837f 0x5b41c5 0x604133 0x606e06 0x606ecc 0x609aa6 0x64d332 0x64d4de 0x7f3ebff44c87 0x5b561a\n",
            "tcmalloc: large alloc 2300993536 bytes == 0xcce54000 @  0x7f3ec03471e7 0x4b2150 0x5ac2ec 0x4fc11a 0x4fe054 0x5ef9b8 0x58eb9c 0x51b4e6 0x58f2a7 0x51740e 0x5b4a3e 0x58f49e 0x51837f 0x5b41c5 0x58f49e 0x51837f 0x5b41c5 0x604133 0x606e06 0x606ecc 0x609aa6 0x64d332 0x64d4de 0x7f3ebff44c87 0x5b561a\n",
            "100% 1142/1142 [00:00<00:00, 6158.55it/s]\n",
            "Saved/birnnscrat_lstm_64_3_100.pth\n",
            "Running eval on test data...\n",
            "100% 36/36 [00:02<00:00, 14.68it/s]\n",
            "\u001b[0m/usr/local/lib/python3.7/dist-packages/ekphrasis/classes/tokenizer.py:225: FutureWarning: Possible nested set at position 2190\n",
            "  self.tok = re.compile(r\"({})\".format(\"|\".join(pipeline)))\n",
            "Reading twitter - 1grams ...\n",
            "Reading twitter - 2grams ...\n",
            "/usr/local/lib/python3.7/dist-packages/ekphrasis/classes/exmanager.py:14: FutureWarning: Possible nested set at position 42\n",
            "  regexes = {k.lower(): re.compile(self.expressions[k]) for k, v in\n",
            "Reading english - 1grams ...\n",
            "tcmalloc: large alloc 2300993536 bytes == 0x4098e000 @  0x7fc82aa3a1e7 0x4b2150 0x5ac2ec 0x5e3d6d 0x58ee7f 0x590c9f 0x591039 0x4fb96a 0x4fc108 0x4fe054 0x5ef9b8 0x58eb9c 0x51b4e6 0x58f2a7 0x51740e 0x5b41c5 0x58f49e 0x51837f 0x5b41c5 0x58f49e 0x51837f 0x5b41c5 0x604133 0x606e06 0x606ecc 0x609aa6 0x64d332 0x64d4de 0x7fc82a637c87 0x5b561a\n",
            "tcmalloc: large alloc 2300993536 bytes == 0xc9bf4000 @  0x7fc82aa3a1e7 0x4b2150 0x5ac2ec 0x4fc11a 0x4fe054 0x5ef9b8 0x58eb9c 0x51b4e6 0x58f2a7 0x51740e 0x5b41c5 0x58f49e 0x51837f 0x5b41c5 0x58f49e 0x51837f 0x5b41c5 0x604133 0x606e06 0x606ecc 0x609aa6 0x64d332 0x64d4de 0x7fc82a637c87 0x5b561a\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:70: FutureWarning: Pass classes=['non-toxic' 'toxic'], y=['non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'non-toxic', 'toxic', 'toxic', 'non-toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'toxic', 'non-toxic'] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
            "  FutureWarning)\n",
            "total_data 1924\n",
            "100% 1924/1924 [00:02<00:00, 687.24it/s]\n",
            "100% 1924/1924 [00:00<00:00, 8624.73it/s]\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:54: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n",
            "Saved/birnnscrat_lstm_64_2_100.pth\n",
            "Running eval on test data...\n",
            "100% 61/61 [00:04<00:00, 14.71it/s]\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!python testing_with_rational.py birnn_scrat 100\n",
        "!python testing_for_bias.py birnn_scrat 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SynOxIW5PY-v",
        "outputId": "1eee9cf5-f198-4356-c0e0-6ed536d30ce2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "bestModel_birnnscrat_100_explanation_top5.json\tbestModel_birnnscrat_bias.json\n"
          ]
        }
      ],
      "source": [
        "!ls explanations_dicts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r1-wjKhvNrF5"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "**Bias Calculation**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GAPagtSDQ9zo"
      },
      "outputs": [],
      "source": [
        "from collections import Counter,defaultdict\n",
        "from tqdm.notebook import tqdm\n",
        "import json\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lFOmyTVIRJ7R"
      },
      "outputs": [],
      "source": [
        "# get_annotated_data method is used to load the dataset\n",
        "from Preprocess.dataCollect import get_annotated_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iw2qaVXLROW4"
      },
      "outputs": [],
      "source": [
        "dict_data_folder={\n",
        "      '2':{'data_file':'Data/dataset.json','class_label':'Data/classes_two.npy'},\n",
        "      '3':{'data_file':'Data/dataset.json','class_label':'Data/classes.npy'}\n",
        "}\n",
        "\n",
        "params = {}\n",
        "\n",
        "# We need to load the dataset with the labels as 'toxic' and 'non-toxic'. \n",
        "# We consider hatespeech and offensive as toxic and normal as non-toxic.\n",
        "params['num_classes']=2  \n",
        "params['data_file']=dict_data_folder[str(params['num_classes'])]['data_file']\n",
        "params['class_names']=dict_data_folder[str(params['num_classes'])]['class_label']\n",
        "\n",
        "data_all_labelled=get_annotated_data(params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 974
        },
        "id": "LDRrrN8CRRfg",
        "outputId": "3728cf84-a1c1-4fd2-ff45-e617eb6a8c0b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-b8e53089-651d-416b-bd70-7520495b1856\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>post_id</th>\n",
              "      <th>text</th>\n",
              "      <th>annotatorid1</th>\n",
              "      <th>target1</th>\n",
              "      <th>label1</th>\n",
              "      <th>annotatorid2</th>\n",
              "      <th>target2</th>\n",
              "      <th>label2</th>\n",
              "      <th>annotatorid3</th>\n",
              "      <th>target3</th>\n",
              "      <th>label3</th>\n",
              "      <th>rationales</th>\n",
              "      <th>final_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1179055004553900032_twitter</td>\n",
              "      <td>[i, dont, think, im, getting, my, baby, them, ...</td>\n",
              "      <td>1</td>\n",
              "      <td>[None]</td>\n",
              "      <td>normal</td>\n",
              "      <td>2</td>\n",
              "      <td>[None]</td>\n",
              "      <td>normal</td>\n",
              "      <td>3</td>\n",
              "      <td>[None]</td>\n",
              "      <td>normal</td>\n",
              "      <td>[]</td>\n",
              "      <td>non-toxic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1179063826874032128_twitter</td>\n",
              "      <td>[we, cannot, continue, calling, ourselves, fem...</td>\n",
              "      <td>1</td>\n",
              "      <td>[None]</td>\n",
              "      <td>normal</td>\n",
              "      <td>2</td>\n",
              "      <td>[None]</td>\n",
              "      <td>normal</td>\n",
              "      <td>3</td>\n",
              "      <td>[None]</td>\n",
              "      <td>normal</td>\n",
              "      <td>[]</td>\n",
              "      <td>non-toxic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1178793830532956161_twitter</td>\n",
              "      <td>[nawt, yall, niggers, ignoring, me]</td>\n",
              "      <td>4</td>\n",
              "      <td>[African]</td>\n",
              "      <td>normal</td>\n",
              "      <td>2</td>\n",
              "      <td>[None]</td>\n",
              "      <td>normal</td>\n",
              "      <td>3</td>\n",
              "      <td>[African]</td>\n",
              "      <td>hatespeech</td>\n",
              "      <td>[]</td>\n",
              "      <td>non-toxic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1179088797964763136_twitter</td>\n",
              "      <td>[&lt;user&gt;, i, am, bit, confused, coz, chinese, p...</td>\n",
              "      <td>1</td>\n",
              "      <td>[Asian]</td>\n",
              "      <td>hatespeech</td>\n",
              "      <td>4</td>\n",
              "      <td>[Asian]</td>\n",
              "      <td>offensive</td>\n",
              "      <td>3</td>\n",
              "      <td>[Asian]</td>\n",
              "      <td>hatespeech</td>\n",
              "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
              "      <td>toxic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1179085312976445440_twitter</td>\n",
              "      <td>[this, bitch, in, whataburger, eating, a, burg...</td>\n",
              "      <td>4</td>\n",
              "      <td>[Caucasian, Women]</td>\n",
              "      <td>hatespeech</td>\n",
              "      <td>2</td>\n",
              "      <td>[Women, Caucasian]</td>\n",
              "      <td>hatespeech</td>\n",
              "      <td>3</td>\n",
              "      <td>[Women, Caucasian]</td>\n",
              "      <td>offensive</td>\n",
              "      <td>[[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
              "      <td>toxic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20143</th>\n",
              "      <td>9989999_gab</td>\n",
              "      <td>[if, ur, still, on, twitter, tell, carlton, i,...</td>\n",
              "      <td>217</td>\n",
              "      <td>[Men, Women, Other]</td>\n",
              "      <td>offensive</td>\n",
              "      <td>199</td>\n",
              "      <td>[None]</td>\n",
              "      <td>offensive</td>\n",
              "      <td>215</td>\n",
              "      <td>[None]</td>\n",
              "      <td>normal</td>\n",
              "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0,...</td>\n",
              "      <td>toxic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20144</th>\n",
              "      <td>9990225_gab</td>\n",
              "      <td>[when, i, first, got, on, here, and, said, i, ...</td>\n",
              "      <td>220</td>\n",
              "      <td>[African]</td>\n",
              "      <td>offensive</td>\n",
              "      <td>223</td>\n",
              "      <td>[African, Other]</td>\n",
              "      <td>offensive</td>\n",
              "      <td>231</td>\n",
              "      <td>[None]</td>\n",
              "      <td>normal</td>\n",
              "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0,...</td>\n",
              "      <td>toxic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20145</th>\n",
              "      <td>9991681_gab</td>\n",
              "      <td>[was, macht, der, moslem, wenn, der, zion, geg...</td>\n",
              "      <td>206</td>\n",
              "      <td>[Islam]</td>\n",
              "      <td>offensive</td>\n",
              "      <td>203</td>\n",
              "      <td>[Other]</td>\n",
              "      <td>normal</td>\n",
              "      <td>211</td>\n",
              "      <td>[None]</td>\n",
              "      <td>normal</td>\n",
              "      <td>[]</td>\n",
              "      <td>non-toxic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20146</th>\n",
              "      <td>9992513_gab</td>\n",
              "      <td>[it, is, awful, look, at, world, demographics,...</td>\n",
              "      <td>209</td>\n",
              "      <td>[Hispanic]</td>\n",
              "      <td>hatespeech</td>\n",
              "      <td>253</td>\n",
              "      <td>[Asian]</td>\n",
              "      <td>hatespeech</td>\n",
              "      <td>222</td>\n",
              "      <td>[Asian]</td>\n",
              "      <td>offensive</td>\n",
              "      <td>[[0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1,...</td>\n",
              "      <td>toxic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20147</th>\n",
              "      <td>9998729_gab</td>\n",
              "      <td>[the, jewish, globalist, elite, have, only, im...</td>\n",
              "      <td>200</td>\n",
              "      <td>[African, Islam]</td>\n",
              "      <td>hatespeech</td>\n",
              "      <td>202</td>\n",
              "      <td>[Islam, Jewish]</td>\n",
              "      <td>offensive</td>\n",
              "      <td>207</td>\n",
              "      <td>[African, Islam, Jewish]</td>\n",
              "      <td>offensive</td>\n",
              "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0,...</td>\n",
              "      <td>toxic</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>20148 rows × 13 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b8e53089-651d-416b-bd70-7520495b1856')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b8e53089-651d-416b-bd70-7520495b1856 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b8e53089-651d-416b-bd70-7520495b1856');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                           post_id  \\\n",
              "0      1179055004553900032_twitter   \n",
              "1      1179063826874032128_twitter   \n",
              "2      1178793830532956161_twitter   \n",
              "3      1179088797964763136_twitter   \n",
              "4      1179085312976445440_twitter   \n",
              "...                            ...   \n",
              "20143                  9989999_gab   \n",
              "20144                  9990225_gab   \n",
              "20145                  9991681_gab   \n",
              "20146                  9992513_gab   \n",
              "20147                  9998729_gab   \n",
              "\n",
              "                                                    text  annotatorid1  \\\n",
              "0      [i, dont, think, im, getting, my, baby, them, ...             1   \n",
              "1      [we, cannot, continue, calling, ourselves, fem...             1   \n",
              "2                    [nawt, yall, niggers, ignoring, me]             4   \n",
              "3      [<user>, i, am, bit, confused, coz, chinese, p...             1   \n",
              "4      [this, bitch, in, whataburger, eating, a, burg...             4   \n",
              "...                                                  ...           ...   \n",
              "20143  [if, ur, still, on, twitter, tell, carlton, i,...           217   \n",
              "20144  [when, i, first, got, on, here, and, said, i, ...           220   \n",
              "20145  [was, macht, der, moslem, wenn, der, zion, geg...           206   \n",
              "20146  [it, is, awful, look, at, world, demographics,...           209   \n",
              "20147  [the, jewish, globalist, elite, have, only, im...           200   \n",
              "\n",
              "                   target1      label1  annotatorid2             target2  \\\n",
              "0                   [None]      normal             2              [None]   \n",
              "1                   [None]      normal             2              [None]   \n",
              "2                [African]      normal             2              [None]   \n",
              "3                  [Asian]  hatespeech             4             [Asian]   \n",
              "4       [Caucasian, Women]  hatespeech             2  [Women, Caucasian]   \n",
              "...                    ...         ...           ...                 ...   \n",
              "20143  [Men, Women, Other]   offensive           199              [None]   \n",
              "20144            [African]   offensive           223    [African, Other]   \n",
              "20145              [Islam]   offensive           203             [Other]   \n",
              "20146           [Hispanic]  hatespeech           253             [Asian]   \n",
              "20147     [African, Islam]  hatespeech           202     [Islam, Jewish]   \n",
              "\n",
              "           label2  annotatorid3                   target3      label3  \\\n",
              "0          normal             3                    [None]      normal   \n",
              "1          normal             3                    [None]      normal   \n",
              "2          normal             3                 [African]  hatespeech   \n",
              "3       offensive             3                   [Asian]  hatespeech   \n",
              "4      hatespeech             3        [Women, Caucasian]   offensive   \n",
              "...           ...           ...                       ...         ...   \n",
              "20143   offensive           215                    [None]      normal   \n",
              "20144   offensive           231                    [None]      normal   \n",
              "20145      normal           211                    [None]      normal   \n",
              "20146  hatespeech           222                   [Asian]   offensive   \n",
              "20147   offensive           207  [African, Islam, Jewish]   offensive   \n",
              "\n",
              "                                              rationales final_label  \n",
              "0                                                     []   non-toxic  \n",
              "1                                                     []   non-toxic  \n",
              "2                                                     []   non-toxic  \n",
              "3      [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...       toxic  \n",
              "4      [[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...       toxic  \n",
              "...                                                  ...         ...  \n",
              "20143  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0,...       toxic  \n",
              "20144  [[0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0,...       toxic  \n",
              "20145                                                 []   non-toxic  \n",
              "20146  [[0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1,...       toxic  \n",
              "20147  [[0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0,...       toxic  \n",
              "\n",
              "[20148 rows x 13 columns]"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_all_labelled"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "14K9-nzFRU8B"
      },
      "outputs": [],
      "source": [
        "def generate_target_information(dataset):\n",
        "    final_target_output = defaultdict(list)\n",
        "    all_communities_selected = []\n",
        "    \n",
        "    for each in dataset.iterrows(): \n",
        "        # All the target communities tagged for this post\n",
        "        all_targets = each[1]['target1']+each[1]['target2']+each[1]['target3']  \n",
        "        community_dict = dict(Counter(all_targets))\n",
        "        \n",
        "        # Select only those communities which are present more than once.\n",
        "        for key in community_dict:\n",
        "            if community_dict[key]>1:  \n",
        "                final_target_output[each[1]['post_id']].append(key)\n",
        "                all_communities_selected.append(key)\n",
        "        \n",
        "        # If no community is selected based on majority voting then we don't select any community\n",
        "        if each[1]['post_id'] not in final_target_output:\n",
        "            final_target_output[each[1]['post_id']].append('None')\n",
        "            all_communities_selected.append(key)\n",
        "\n",
        "    return final_target_output, all_communities_selected"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mEmm7AD9Ra13"
      },
      "outputs": [],
      "source": [
        "target_information, all_communities_selected = generate_target_information(data_all_labelled)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LPCh_pj3ReFA",
        "outputId": "0f646ce2-49a2-42fe-e541-49a468df6a44"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['African',\n",
              " 'Islam',\n",
              " 'Jewish',\n",
              " 'Homosexual',\n",
              " 'Women',\n",
              " 'Refugee',\n",
              " 'Arab',\n",
              " 'Caucasian',\n",
              " 'Asian',\n",
              " 'Hispanic']"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "community_count_dict = Counter(all_communities_selected)\n",
        "\n",
        "# We remove None and Other from dictionary\n",
        "community_count_dict.pop('None')\n",
        "community_count_dict.pop('Other')\n",
        "\n",
        "# For the bias calculation, we are considering the top 10 communites based on their count\n",
        "list_selected_community = [community for community, value in community_count_dict.most_common(10)]\n",
        "list_selected_community"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eRU3peSrRhVo"
      },
      "outputs": [],
      "source": [
        "# Based on the top 10 communities, we filter the target_information\n",
        "# This will remove the other communities from the calculation\n",
        "\n",
        "final_target_information ={}\n",
        "for each in target_information:\n",
        "    temp = list(set(target_information[each])&set(list_selected_community))\n",
        "    if len(temp) == 0:\n",
        "        final_target_information[each] = None\n",
        "    else:\n",
        "        final_target_information[each] = temp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BEsvl0xaRkpw"
      },
      "outputs": [],
      "source": [
        "# Add a new column 'final_target_category' which will contain the selected target community names\n",
        "data_all_labelled['final_target_category'] = data_all_labelled['post_id'].map(final_target_information)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "L0-Y6iMiRnxH",
        "outputId": "cb51d01d-a460-4a11-9e09-94ce9f88b3ea"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-df176601-25d6-425c-820a-907d4bd1b646\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>post_id</th>\n",
              "      <th>text</th>\n",
              "      <th>annotatorid1</th>\n",
              "      <th>target1</th>\n",
              "      <th>label1</th>\n",
              "      <th>annotatorid2</th>\n",
              "      <th>target2</th>\n",
              "      <th>label2</th>\n",
              "      <th>annotatorid3</th>\n",
              "      <th>target3</th>\n",
              "      <th>label3</th>\n",
              "      <th>rationales</th>\n",
              "      <th>final_label</th>\n",
              "      <th>final_target_category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1179055004553900032_twitter</td>\n",
              "      <td>[i, dont, think, im, getting, my, baby, them, ...</td>\n",
              "      <td>1</td>\n",
              "      <td>[None]</td>\n",
              "      <td>normal</td>\n",
              "      <td>2</td>\n",
              "      <td>[None]</td>\n",
              "      <td>normal</td>\n",
              "      <td>3</td>\n",
              "      <td>[None]</td>\n",
              "      <td>normal</td>\n",
              "      <td>[]</td>\n",
              "      <td>non-toxic</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>13851720_gab</td>\n",
              "      <td>[laura, loomer, raped, me, while, screaming, a...</td>\n",
              "      <td>1</td>\n",
              "      <td>[Jewish]</td>\n",
              "      <td>hatespeech</td>\n",
              "      <td>2</td>\n",
              "      <td>[Jewish]</td>\n",
              "      <td>hatespeech</td>\n",
              "      <td>3</td>\n",
              "      <td>[Jewish]</td>\n",
              "      <td>hatespeech</td>\n",
              "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0,...</td>\n",
              "      <td>toxic</td>\n",
              "      <td>[Jewish]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>1178818409812746240_twitter</td>\n",
              "      <td>[&lt;user&gt;, what, did, the, old, lady, do, was, s...</td>\n",
              "      <td>9</td>\n",
              "      <td>[None]</td>\n",
              "      <td>normal</td>\n",
              "      <td>10</td>\n",
              "      <td>[None]</td>\n",
              "      <td>normal</td>\n",
              "      <td>4</td>\n",
              "      <td>[None]</td>\n",
              "      <td>normal</td>\n",
              "      <td>[]</td>\n",
              "      <td>non-toxic</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>19346774_gab</td>\n",
              "      <td>[as, much, as, i, appreciate, a, format, of, o...</td>\n",
              "      <td>9</td>\n",
              "      <td>[None]</td>\n",
              "      <td>normal</td>\n",
              "      <td>13</td>\n",
              "      <td>[None]</td>\n",
              "      <td>normal</td>\n",
              "      <td>4</td>\n",
              "      <td>[Hispanic]</td>\n",
              "      <td>offensive</td>\n",
              "      <td>[]</td>\n",
              "      <td>non-toxic</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>1165819983701643266_twitter</td>\n",
              "      <td>[sex, be, so, good, a, bitch, be, slow, stroki...</td>\n",
              "      <td>4</td>\n",
              "      <td>[Women]</td>\n",
              "      <td>offensive</td>\n",
              "      <td>7</td>\n",
              "      <td>[Women]</td>\n",
              "      <td>offensive</td>\n",
              "      <td>16</td>\n",
              "      <td>[None]</td>\n",
              "      <td>normal</td>\n",
              "      <td>[[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 0, ...</td>\n",
              "      <td>toxic</td>\n",
              "      <td>[Women]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20105</th>\n",
              "      <td>9773208_gab</td>\n",
              "      <td>[it, always, women, trying, this, shit, like, ...</td>\n",
              "      <td>200</td>\n",
              "      <td>[Women]</td>\n",
              "      <td>hatespeech</td>\n",
              "      <td>202</td>\n",
              "      <td>[Women]</td>\n",
              "      <td>offensive</td>\n",
              "      <td>203</td>\n",
              "      <td>[Women]</td>\n",
              "      <td>offensive</td>\n",
              "      <td>[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...</td>\n",
              "      <td>toxic</td>\n",
              "      <td>[Women]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20109</th>\n",
              "      <td>9802943_gab</td>\n",
              "      <td>[because, women, would, never, lie, about, bei...</td>\n",
              "      <td>228</td>\n",
              "      <td>[Women]</td>\n",
              "      <td>offensive</td>\n",
              "      <td>222</td>\n",
              "      <td>[Women]</td>\n",
              "      <td>offensive</td>\n",
              "      <td>209</td>\n",
              "      <td>[Women]</td>\n",
              "      <td>normal</td>\n",
              "      <td>[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...</td>\n",
              "      <td>toxic</td>\n",
              "      <td>[Women]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20117</th>\n",
              "      <td>9826963_gab</td>\n",
              "      <td>[how, is, all, that, awesome, muslim, diversit...</td>\n",
              "      <td>228</td>\n",
              "      <td>[Islam]</td>\n",
              "      <td>offensive</td>\n",
              "      <td>222</td>\n",
              "      <td>[Islam]</td>\n",
              "      <td>offensive</td>\n",
              "      <td>209</td>\n",
              "      <td>[Islam]</td>\n",
              "      <td>offensive</td>\n",
              "      <td>[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...</td>\n",
              "      <td>toxic</td>\n",
              "      <td>[Islam]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20128</th>\n",
              "      <td>9867117_gab</td>\n",
              "      <td>[well, my, dear, lgbtq, brothers, and, sisters...</td>\n",
              "      <td>207</td>\n",
              "      <td>[Islam, Other]</td>\n",
              "      <td>offensive</td>\n",
              "      <td>223</td>\n",
              "      <td>[Islam]</td>\n",
              "      <td>hatespeech</td>\n",
              "      <td>231</td>\n",
              "      <td>[Islam]</td>\n",
              "      <td>hatespeech</td>\n",
              "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
              "      <td>toxic</td>\n",
              "      <td>[Islam]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20130</th>\n",
              "      <td>9869181_gab</td>\n",
              "      <td>[but, it, on, hbo, more, violence, and, sex, c...</td>\n",
              "      <td>223</td>\n",
              "      <td>[None]</td>\n",
              "      <td>normal</td>\n",
              "      <td>200</td>\n",
              "      <td>[None]</td>\n",
              "      <td>normal</td>\n",
              "      <td>233</td>\n",
              "      <td>[None]</td>\n",
              "      <td>normal</td>\n",
              "      <td>[]</td>\n",
              "      <td>non-toxic</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1924 rows × 14 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-df176601-25d6-425c-820a-907d4bd1b646')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-df176601-25d6-425c-820a-907d4bd1b646 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-df176601-25d6-425c-820a-907d4bd1b646');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                           post_id  \\\n",
              "0      1179055004553900032_twitter   \n",
              "5                     13851720_gab   \n",
              "17     1178818409812746240_twitter   \n",
              "25                    19346774_gab   \n",
              "36     1165819983701643266_twitter   \n",
              "...                            ...   \n",
              "20105                  9773208_gab   \n",
              "20109                  9802943_gab   \n",
              "20117                  9826963_gab   \n",
              "20128                  9867117_gab   \n",
              "20130                  9869181_gab   \n",
              "\n",
              "                                                    text  annotatorid1  \\\n",
              "0      [i, dont, think, im, getting, my, baby, them, ...             1   \n",
              "5      [laura, loomer, raped, me, while, screaming, a...             1   \n",
              "17     [<user>, what, did, the, old, lady, do, was, s...             9   \n",
              "25     [as, much, as, i, appreciate, a, format, of, o...             9   \n",
              "36     [sex, be, so, good, a, bitch, be, slow, stroki...             4   \n",
              "...                                                  ...           ...   \n",
              "20105  [it, always, women, trying, this, shit, like, ...           200   \n",
              "20109  [because, women, would, never, lie, about, bei...           228   \n",
              "20117  [how, is, all, that, awesome, muslim, diversit...           228   \n",
              "20128  [well, my, dear, lgbtq, brothers, and, sisters...           207   \n",
              "20130  [but, it, on, hbo, more, violence, and, sex, c...           223   \n",
              "\n",
              "              target1      label1  annotatorid2   target2      label2  \\\n",
              "0              [None]      normal             2    [None]      normal   \n",
              "5            [Jewish]  hatespeech             2  [Jewish]  hatespeech   \n",
              "17             [None]      normal            10    [None]      normal   \n",
              "25             [None]      normal            13    [None]      normal   \n",
              "36            [Women]   offensive             7   [Women]   offensive   \n",
              "...               ...         ...           ...       ...         ...   \n",
              "20105         [Women]  hatespeech           202   [Women]   offensive   \n",
              "20109         [Women]   offensive           222   [Women]   offensive   \n",
              "20117         [Islam]   offensive           222   [Islam]   offensive   \n",
              "20128  [Islam, Other]   offensive           223   [Islam]  hatespeech   \n",
              "20130          [None]      normal           200    [None]      normal   \n",
              "\n",
              "       annotatorid3     target3      label3  \\\n",
              "0                 3      [None]      normal   \n",
              "5                 3    [Jewish]  hatespeech   \n",
              "17                4      [None]      normal   \n",
              "25                4  [Hispanic]   offensive   \n",
              "36               16      [None]      normal   \n",
              "...             ...         ...         ...   \n",
              "20105           203     [Women]   offensive   \n",
              "20109           209     [Women]      normal   \n",
              "20117           209     [Islam]   offensive   \n",
              "20128           231     [Islam]  hatespeech   \n",
              "20130           233      [None]      normal   \n",
              "\n",
              "                                              rationales final_label  \\\n",
              "0                                                     []   non-toxic   \n",
              "5      [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0,...       toxic   \n",
              "17                                                    []   non-toxic   \n",
              "25                                                    []   non-toxic   \n",
              "36     [[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 0, ...       toxic   \n",
              "...                                                  ...         ...   \n",
              "20105  [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...       toxic   \n",
              "20109  [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...       toxic   \n",
              "20117  [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...       toxic   \n",
              "20128  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...       toxic   \n",
              "20130                                                 []   non-toxic   \n",
              "\n",
              "      final_target_category  \n",
              "0                      None  \n",
              "5                  [Jewish]  \n",
              "17                     None  \n",
              "25                     None  \n",
              "36                  [Women]  \n",
              "...                     ...  \n",
              "20105               [Women]  \n",
              "20109               [Women]  \n",
              "20117               [Islam]  \n",
              "20128               [Islam]  \n",
              "20130                  None  \n",
              "\n",
              "[1924 rows x 14 columns]"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# The post_id_divisions file stores the train, val, test split ids. We select only the test ids.\n",
        "postpost_id_divisions_path = './Data/post_id_divisions.json'\n",
        "\n",
        "with open(postpost_id_divisions_path, 'r') as fp:\n",
        "    post_id_dict=json.load(fp)\n",
        "\n",
        "data_all_labelled_bias = data_all_labelled[data_all_labelled['post_id'].isin(post_id_dict['test'])]\n",
        "data_all_labelled_bias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uT3uzWgcRqaf"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# The names of the files which will contain the bias output for each model\n",
        "bias_score_file_mapping={\n",
        "    'BiRNN-Attn':'bestModel_birnnscrat_bias.json',\n",
        "}\n",
        "\n",
        "# The parent folder path of the bias output files\n",
        "parent_path = './explanations_dicts/'\n",
        "\n",
        "# The bias methods that will be considered\n",
        "method_list = ['subgroup', 'bpsn', 'bnsp']\n",
        "\n",
        "community_list = list(list_selected_community)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X0H9nMZNR1v3"
      },
      "outputs": [],
      "source": [
        "# This function is used to convert the classification into a [0-1] score \n",
        "# with a value of 0 meaning non-toxic and 1 meaning toxic\n",
        "def convert_to_score(label_name, label_dict):\n",
        "    if label_name=='non-toxic':\n",
        "        return 1-label_dict[label_name]\n",
        "    else:\n",
        "        return label_dict[label_name]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qUFyY8iVR4kn"
      },
      "outputs": [],
      "source": [
        "# Function to divide the ids into postive or class class based on the method.\n",
        "def bias_evaluation_metric(dataset, method, community):\n",
        "    positive_ids = []\n",
        "    negative_ids = []\n",
        "    if method=='subgroup':\n",
        "        for eachrow in dataset.iterrows():\n",
        "            if eachrow[1]['final_target_category'] == None:\n",
        "                continue\n",
        "            if community in eachrow[1]['final_target_category']:\n",
        "                if eachrow[1]['final_label'] =='non-toxic':\n",
        "                    negative_ids.append(eachrow[1]['post_id'])\n",
        "                else:\n",
        "                    positive_ids.append(eachrow[1]['post_id'])\n",
        "            else:\n",
        "                pass\n",
        "    elif method=='bpsn':\n",
        "        for eachrow in dataset.iterrows():\n",
        "            if eachrow[1]['final_target_category'] == None:\n",
        "                continue\n",
        "            if community in eachrow[1]['final_target_category']:\n",
        "#                 print(eachrow[1]['final_label'])\n",
        "                if eachrow[1]['final_label'] =='non-toxic':\n",
        "                    negative_ids.append(eachrow[1]['post_id'])\n",
        "                else:\n",
        "                    pass\n",
        "            else:\n",
        "                if eachrow[1]['final_label'] !='non-toxic':\n",
        "                    positive_ids.append(eachrow[1]['post_id'])\n",
        "                else:\n",
        "                    pass\n",
        "    elif method=='bnsp':\n",
        "        for eachrow in dataset.iterrows():\n",
        "            if eachrow[1]['final_target_category'] == None:\n",
        "                continue\n",
        "            if community in eachrow[1]['final_target_category']:\n",
        "                if eachrow[1]['final_label'] !='non-toxic':\n",
        "                    positive_ids.append(eachrow[1]['post_id'])\n",
        "                else:\n",
        "                    pass\n",
        "            else:\n",
        "                if eachrow[1]['final_label'] =='non-toxic':\n",
        "                    negative_ids.append(eachrow[1]['post_id'])\n",
        "                else:\n",
        "                    pass\n",
        "    else:\n",
        "        print('Incorrect option selected!!!')\n",
        "                \n",
        "    return {'positiveID':positive_ids, 'negativeID':negative_ids}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "cc692a0b6b5845c3bf604a5ad0e7dbdd",
            "60572c420e8f426683f2331771d36daa",
            "cd51b8b4b9da4ffab7e407db60c05877",
            "e3d5bc1600594855b5e801060fa7ceaa",
            "f1a8a21af6924b3d882dfd54ecbf052f",
            "bae8d09e7b0b424d8ec80abb5fd07af0",
            "dcd50a06f28a41bbbd34be4d3b76489d",
            "6ac1bc64f4d54b46adf8d88e1f17bdda"
          ]
        },
        "id": "_o-CBxRFR7YQ",
        "outputId": "abdb9bfa-0254-4a2a-8fe2-8f7a73a5b037"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cc692a0b6b5845c3bf604a5ad0e7dbdd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "final_bias_dictionary = defaultdict(lambda: defaultdict(dict))\n",
        "\n",
        "# We load each of the model bias output file and compute the bias score using each method for all the community\n",
        "for each_model in tqdm(bias_score_file_mapping):\n",
        "    total_data ={}\n",
        "    with open(parent_path+bias_score_file_mapping[each_model]) as fp:\n",
        "        for line in fp:\n",
        "            data = json.loads(line)\n",
        "            total_data[data['annotation_id']] = data\n",
        "    for each_method in method_list:\n",
        "        for each_community in community_list:\n",
        "            community_data = bias_evaluation_metric(data_all_labelled_bias, each_method, each_community)\n",
        "            truth_values = []\n",
        "            prediction_values = []\n",
        "\n",
        "\n",
        "            label_to_value = {'toxic':1.0, 'non-toxic':0.0}\n",
        "            for each in community_data['positiveID']:\n",
        "                truth_values.append(label_to_value[total_data[each]['ground_truth']])\n",
        "                prediction_values.append(convert_to_score(total_data[each]['classification'], total_data[each]['classification_scores']))\n",
        "\n",
        "            for each in community_data['negativeID']:\n",
        "                truth_values.append(label_to_value[total_data[each]['ground_truth']])\n",
        "                prediction_values.append(convert_to_score(total_data[each]['classification'], total_data[each]['classification_scores']))\n",
        "\n",
        "            roc_output_value = roc_auc_score(truth_values, prediction_values)\n",
        "            final_bias_dictionary[each_model][each_method][each_community] = roc_output_value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "_uoz4r8JR-23",
        "outputId": "f749cf94-00a8-488a-da70-e64f68893460"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'%.4f'"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%precision 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PIQi-Am9SCIz",
        "outputId": "0bb9828e-f1b5-416e-d972-0566de3600ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BiRNN-Attn subgroup 0.7178253973318881\n",
            "BiRNN-Attn bpsn 0.6412719177169195\n",
            "BiRNN-Attn bnsp 0.706659682390115\n"
          ]
        }
      ],
      "source": [
        "# To combine the per-identity Bias AUCs into one overall measure, we calculate their generalized mean as defined below:\n",
        "power_value = -5\n",
        "num_communities = len(community_list)\n",
        "\n",
        "for each_model in final_bias_dictionary:\n",
        "    for each_method in final_bias_dictionary[each_model]:\n",
        "        temp_value =[]\n",
        "        for each_community in final_bias_dictionary[each_model][each_method]:\n",
        "            temp_value.append(pow(final_bias_dictionary[each_model][each_method][each_community], power_value))\n",
        "        print(each_model, each_method, pow(np.sum(temp_value)/num_communities, 1/power_value))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jx1-xKrKSFza"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cos2FyRyScI6"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**Explainability Calculation**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L0n04ccES0G3"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from tqdm.notebook import tqdm\n",
        "import more_itertools as mit\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DQ37OLVZS8gB"
      },
      "outputs": [],
      "source": [
        "# get_annotated_data method is used to load the dataset\n",
        "from Preprocess import *\n",
        "from Preprocess.dataCollect import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8AZCJG3wS-ko"
      },
      "outputs": [],
      "source": [
        "dict_data_folder={\n",
        "      '2':{'data_file':'Data/dataset.json','class_label':'Data/classes_two.npy'},\n",
        "      '3':{'data_file':'Data/dataset.json','class_label':'Data/classes.npy'}\n",
        "}\n",
        "\n",
        "# We need to load the dataset with the labels as 'hatespeech', 'offensive', and 'normal' (3-class). \n",
        "\n",
        "params = {}\n",
        "params['num_classes']=3\n",
        "params['data_file']=dict_data_folder[str(params['num_classes'])]['data_file']\n",
        "params['class_names']=dict_data_folder[str(params['num_classes'])]['class_label']\n",
        "\n",
        "data_all_labelled=get_annotated_data(params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H5DLppxPTAjo",
        "outputId": "65b8cd13-26fc-4791-a586-1166b0a5fa45"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading Normal tokenizer...\n"
          ]
        }
      ],
      "source": [
        "# The important key here is the 'bert_token'. Set it to True for Bert based models and False for Others.\n",
        "\n",
        "params_data={\n",
        "    'include_special':False,  #True is want to include <url> in place of urls if False will be removed\n",
        "    'bert_tokens':False, #True /False\n",
        "    'type_attention':'softmax', #softmax\n",
        "    'set_decay':0.1,\n",
        "    'majority':2,\n",
        "    'max_length':128,\n",
        "    'variance':10,\n",
        "    'window':4,\n",
        "    'alpha':0.5,\n",
        "    'p_value':0.8,\n",
        "    'method':'additive',\n",
        "    'decay':False,\n",
        "    'normalized':False,\n",
        "    'not_recollect':True,\n",
        "}\n",
        "\n",
        "\n",
        "if(params_data['bert_tokens']):\n",
        "    print('Loading BERT tokenizer...')\n",
        "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=False)\n",
        "else:\n",
        "    print('Loading Normal tokenizer...')\n",
        "    tokenizer=None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aqwkmy9ITEvH"
      },
      "outputs": [],
      "source": [
        "# Load the whole dataset and get the tokenwise rationales\n",
        "def get_training_data(data):\n",
        "    post_ids_list=[]\n",
        "    text_list=[]\n",
        "    attention_list=[]\n",
        "    label_list=[]\n",
        "    \n",
        "    final_binny_output = []\n",
        "    print('total_data',len(data))\n",
        "    for index,row in tqdm(data.iterrows(),total=len(data)):\n",
        "        annotation=row['final_label']\n",
        "        \n",
        "        text=row['text']\n",
        "        post_id=row['post_id']\n",
        "        annotation_list=[row['label1'],row['label2'],row['label3']]\n",
        "        tokens_all = list(row['text'])\n",
        "#         attention_masks =  [list(row['explain1']),list(row['explain2']),list(row['explain1'])]\n",
        "        \n",
        "        if(annotation!= 'undecided'):\n",
        "            tokens_all,attention_masks=returnMask(row, params_data, tokenizer)\n",
        "            final_binny_output.append([post_id, annotation, tokens_all, attention_masks, annotation_list])\n",
        "\n",
        "    return final_binny_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S2lkIo1ATHjH",
        "outputId": "a0f030b8-c734-4286-bdd7-616e799732f8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 65/20148 [00:00<00:31, 638.99it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total_data 20148\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20148/20148 [00:29<00:00, 683.25it/s]\n"
          ]
        }
      ],
      "source": [
        "training_data=get_training_data(data_all_labelled)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QZxfQUvdTJzn"
      },
      "outputs": [],
      "source": [
        "# https://stackoverflow.com/questions/2154249/identify-groups-of-continuous-numbers-in-a-list\n",
        "def find_ranges(iterable):\n",
        "    \"\"\"Yield range of consecutive numbers.\"\"\"\n",
        "    for group in mit.consecutive_groups(iterable):\n",
        "        group = list(group)\n",
        "        if len(group) == 1:\n",
        "            yield group[0]\n",
        "        else:\n",
        "            yield group[0], group[-1]\n",
        "            \n",
        "# Convert dataset into ERASER format: https://github.com/jayded/eraserbenchmark/blob/master/rationale_benchmark/utils.py\n",
        "def get_evidence(post_id, anno_text, explanations):\n",
        "    output = []\n",
        "\n",
        "    indexes = sorted([i for i, each in enumerate(explanations) if each==1])\n",
        "    span_list = list(find_ranges(indexes))\n",
        "\n",
        "    for each in span_list:\n",
        "        if type(each)== int:\n",
        "            start = each\n",
        "            end = each+1\n",
        "        elif len(each) == 2:\n",
        "            start = each[0]\n",
        "            end = each[1]+1\n",
        "        else:\n",
        "            print('error')\n",
        "\n",
        "        output.append({\"docid\":post_id, \n",
        "              \"end_sentence\": -1, \n",
        "              \"end_token\": end, \n",
        "              \"start_sentence\": -1, \n",
        "              \"start_token\": start, \n",
        "              \"text\": ' '.join([str(x) for x in anno_text[start:end]])})\n",
        "    return output\n",
        "\n",
        "# To use the metrices defined in ERASER, we will have to convert the dataset\n",
        "def convert_to_eraser_format(dataset, method, save_split, save_path, id_division):  \n",
        "    final_output = []\n",
        "    \n",
        "    if save_split:\n",
        "        train_fp = open(save_path+'train.jsonl', 'w')\n",
        "        val_fp = open(save_path+'val.jsonl', 'w')\n",
        "        test_fp = open(save_path+'test.jsonl', 'w')\n",
        "            \n",
        "    for tcount, eachrow in enumerate(dataset):\n",
        "        \n",
        "        temp = {}\n",
        "        post_id = eachrow[0]\n",
        "        post_class = eachrow[1]\n",
        "        anno_text_list = eachrow[2]\n",
        "        majority_label = eachrow[1]\n",
        "        \n",
        "        if majority_label=='normal':\n",
        "            continue\n",
        "        \n",
        "        all_labels = eachrow[4]\n",
        "        explanations = []\n",
        "        for each_explain in eachrow[3]:\n",
        "            explanations.append(list(each_explain))\n",
        "        \n",
        "        # For this work, we have considered the union of explanations. Other options could be explored as well.\n",
        "        if method == 'union':\n",
        "            final_explanation = [any(each) for each in zip(*explanations)]\n",
        "            final_explanation = [int(each) for each in final_explanation]\n",
        "        \n",
        "            \n",
        "        temp['annotation_id'] = post_id\n",
        "        temp['classification'] = post_class\n",
        "        temp['evidences'] = [get_evidence(post_id, list(anno_text_list), final_explanation)]\n",
        "        temp['query'] = \"What is the class?\"\n",
        "        temp['query_type'] = None\n",
        "        final_output.append(temp)\n",
        "        \n",
        "        if save_split:\n",
        "            if not os.path.exists(save_path+'docs'):\n",
        "                os.makedirs(save_path+'docs')\n",
        "            \n",
        "            with open(save_path+'docs/'+post_id, 'w') as fp:\n",
        "                fp.write(' '.join([str(x) for x in list(anno_text_list)]))\n",
        "            \n",
        "            if post_id in id_division['train']:\n",
        "                train_fp.write(json.dumps(temp)+'\\n')\n",
        "            \n",
        "            elif post_id in id_division['val']:\n",
        "                val_fp.write(json.dumps(temp)+'\\n')\n",
        "            \n",
        "            elif post_id in id_division['test']:\n",
        "                test_fp.write(json.dumps(temp)+'\\n')\n",
        "            else:\n",
        "                print(post_id)\n",
        "    \n",
        "    if save_split:\n",
        "        train_fp.close()\n",
        "        val_fp.close()\n",
        "        test_fp.close()\n",
        "        \n",
        "    return final_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "deYKnU3wTRJn"
      },
      "outputs": [],
      "source": [
        "# The post_id_divisions file stores the train, val, test split ids. We select only the test ids.\n",
        "with open('./Data/post_id_divisions.json') as fp:\n",
        "    id_division = json.load(fp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XlA0iMeETjUd"
      },
      "outputs": [],
      "source": [
        "!mkdir ./Data/Evaluation\n",
        "!mkdir ./Data/Evaluation/Model_Eval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B2XwjEPOTUaY"
      },
      "outputs": [],
      "source": [
        "method = 'union'\n",
        "save_split = True\n",
        "save_path = './Data/Evaluation/Model_Eval/'  #The dataset in Eraser Format will be stored here.\n",
        "output_eraser = convert_to_eraser_format(training_data, method, save_split, save_path, id_division)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e76FcTICTXrX",
        "outputId": "dc1c2307-ee84-4a4e-f40a-00137197eec0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "docs  test.jsonl  train.jsonl  val.jsonl\n"
          ]
        }
      ],
      "source": [
        "!ls Data/Evaluation/Model_Eval/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L9lpwdAeTaf_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kMWLQB2uT28g",
        "outputId": "0b33f6d3-58d4-4d1a-8ae7-1bc901eab632"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "best_model_json\t\t\t     Models\n",
            "best_runs.sh\t\t\t     Parameters_description.md\n",
            "Bias_Calculation_NB.ipynb\t     parameters_selection.py\n",
            "convert_to_word2vec.py\t\t     Preprocess\n",
            "Data\t\t\t\t     __pycache__\n",
            "eraserbenchmark\t\t\t     README.md\n",
            "Example_HateExplain.ipynb\t     requirements.txt\n",
            "Explainability_Calculation_NB.ipynb  Saved\n",
            "explanations_dicts\t\t     TensorDataset\n",
            "Figures\t\t\t\t     testing_for_bias.py\n",
            "LICENSE\t\t\t\t     testing_with_lime.py\n",
            "manual_training_inference.py\t     testing_with_rational.py\n",
            "model_explain_output.json\t     test_parallel.sh\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ylHvxsmoUv7Q",
        "outputId": "5193fdaa-8ea2-41a7-bb60-c121e40a2688"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/HateXplain/eraserbenchmark\n"
          ]
        }
      ],
      "source": [
        "cd eraserbenchmark/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SajAK6cMUyt6",
        "outputId": "ecdd495c-e6e7-41a1-e5e6-c419783aa9ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "data_exploration.ipynb\tparams\t\t     README.md\t       requirements.txt\n",
            "LICENSE\t\t\trationale_benchmark  REPRODUCTION.txt\n"
          ]
        }
      ],
      "source": [
        "!ls "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0iudyL6lcXib"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GzZLhJf-U8Vf",
        "outputId": "7d08fd59-f246-4ac8-fb81-8a07f6a3d0ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  1717 MainThread Error in instances: 0 instances fail validation: set()\n",
            "  3234 MainThread No sentence level predictions detected, skipping sentence-level diagnostic\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "{'classification_scores': {'accuracy': 0.6217162872154116,\n",
            "                           'aopc_thresholds': None,\n",
            "                           'comprehensiveness': 0.2899375320616098,\n",
            "                           'comprehensiveness_aopc': None,\n",
            "                           'comprehensiveness_aopc_points': None,\n",
            "                           'comprehensiveness_entropy': 0.06618782785757517,\n",
            "                           'comprehensiveness_kl': 0.6169633591014108,\n",
            "                           'prf': {'accuracy': 0.6217162872154116,\n",
            "                                   'hatespeech': {'f1-score': 0.776888888888889,\n",
            "                                                  'precision': 0.8229755178907722,\n",
            "                                                  'recall': 0.7356902356902357,\n",
            "                                                  'support': 594},\n",
            "                                   'macro avg': {'f1-score': 0.45722004357298474,\n",
            "                                                 'precision': 0.5202711185762033,\n",
            "                                                 'recall': 0.4112884727239958,\n",
            "                                                 'support': 1142},\n",
            "                                   'normal': {'f1-score': 0.0,\n",
            "                                              'precision': 0.0,\n",
            "                                              'recall': 0.0,\n",
            "                                              'support': 0},\n",
            "                                   'offensive': {'f1-score': 0.5947712418300654,\n",
            "                                                 'precision': 0.7378378378378379,\n",
            "                                                 'recall': 0.4981751824817518,\n",
            "                                                 'support': 548},\n",
            "                                   'weighted avg': {'f1-score': 0.6894979339079474,\n",
            "                                                    'precision': 0.7821213596867371,\n",
            "                                                    'recall': 0.6217162872154116,\n",
            "                                                    'support': 1142}},\n",
            "                           'sufficiency': 0.0014583442993005395,\n",
            "                           'sufficiency_aopc': None,\n",
            "                           'sufficiency_aopc_points': None,\n",
            "                           'sufficiency_entropy': 0.036175898599931006,\n",
            "                           'sufficiency_kl': 0.03766218336473326},\n",
            " 'iou_scores': [{'macro': {'f1': 0.22809206487116668,\n",
            "                           'p': 0.14788382953882084,\n",
            "                           'r': 0.49842381786339757},\n",
            "                 'micro': {'f1': 0.22626646747249762,\n",
            "                           'p': 0.147069209039548,\n",
            "                           'r': 0.49028840494408477},\n",
            "                 'threshold': 0.5}],\n",
            " 'rationale_prf': {'instance_macro': {'f1': 0.11631116013778008,\n",
            "                                      'p': 0.07850262697022814,\n",
            "                                      'r': 0.26409807355516635},\n",
            "                   'instance_micro': {'f1': 0.12033138666304496,\n",
            "                                      'p': 0.0782132768361582,\n",
            "                                      'r': 0.2607416127133608}},\n",
            " 'token_prf': {'instance_macro': {'f1': 0.5074295479278655,\n",
            "                                  'p': 0.6181990659661416,\n",
            "                                  'r': 0.6430023805548015},\n",
            "               'instance_micro': {'f1': 0.44232469993682877,\n",
            "                                  'p': 0.618114406779661,\n",
            "                                  'r': 0.34438323824513084}},\n",
            " 'token_soft_metrics': {'auprc': 0.8384250389403275,\n",
            "                        'average_precision': 0.8342252704971385,\n",
            "                        'roc_auc_score': 0.8541055365711129}}\n"
          ]
        }
      ],
      "source": [
        "!PYTHONPATH=./:$PYTHONPATH python rationale_benchmark/metrics.py --split test  --data_dir ../Data/Evaluation/Model_Eval --results ../explanations_dicts/bestModel_birnnscrat_100_explanation_top5.json --score_file ../model_explain_output.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D1eQENR4VLp_",
        "outputId": "b81634c8-0264-4834-8d23-d0eb107566af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Plausibility\n",
            "IOU F1 : 0.22809206487116668\n",
            "Token F1 : 0.5074295479278655\n",
            "AUPRC : 0.8384250389403275\n",
            "\n",
            "Faithfulness\n",
            "Comprehensiveness : 0.2899375320616098\n",
            "Sufficiency 0.0014583442993005395\n"
          ]
        }
      ],
      "source": [
        "# print the required results\n",
        "with open('../model_explain_output.json') as fp:\n",
        "    output_data = json.load(fp)\n",
        "\n",
        "print('\\nPlausibility')\n",
        "print('IOU F1 :', output_data['iou_scores'][0]['macro']['f1'])\n",
        "print('Token F1 :', output_data['token_prf']['instance_macro']['f1'])\n",
        "print('AUPRC :', output_data['token_soft_metrics']['auprc'])\n",
        "\n",
        "print('\\nFaithfulness')\n",
        "print('Comprehensiveness :', output_data['classification_scores']['comprehensiveness'])\n",
        "print('Sufficiency', output_data['classification_scores']['sufficiency'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ND6DYOMxTU8A"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "60572c420e8f426683f2331771d36daa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "100%",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f1a8a21af6924b3d882dfd54ecbf052f",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bae8d09e7b0b424d8ec80abb5fd07af0",
            "value": 1
          }
        },
        "6ac1bc64f4d54b46adf8d88e1f17bdda": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bae8d09e7b0b424d8ec80abb5fd07af0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": "initial"
          }
        },
        "cc692a0b6b5845c3bf604a5ad0e7dbdd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_60572c420e8f426683f2331771d36daa",
              "IPY_MODEL_cd51b8b4b9da4ffab7e407db60c05877"
            ],
            "layout": "IPY_MODEL_e3d5bc1600594855b5e801060fa7ceaa"
          }
        },
        "cd51b8b4b9da4ffab7e407db60c05877": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dcd50a06f28a41bbbd34be4d3b76489d",
            "placeholder": "​",
            "style": "IPY_MODEL_6ac1bc64f4d54b46adf8d88e1f17bdda",
            "value": " 1/1 [00:43&lt;00:00, 43.50s/it]"
          }
        },
        "dcd50a06f28a41bbbd34be4d3b76489d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3d5bc1600594855b5e801060fa7ceaa": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f1a8a21af6924b3d882dfd54ecbf052f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}